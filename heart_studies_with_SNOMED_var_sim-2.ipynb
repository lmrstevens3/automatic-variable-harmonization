{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automatic_variable_mapping import corpus, vocab_similarity\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import time\n",
    "import numpy as np\n",
    "from automatic_variable_mapping.vocab_similarity import default_pairable\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obs Heart Studies\n",
    "#input_data_type = \"obs_heart_studies_dbGaP_NLP\"\n",
    "#ref_id_col = 'dbGaP_studyID_datasetID_varID'\n",
    "#doc_cols_inputs = {\n",
    "#     'desc': ['variable_description'],\n",
    "#     'units': ['units'],\n",
    "#     'coding': ['variable_coding_counts_distribution'],\n",
    "#     #'desc_units': ['variable_description', 'units'],\n",
    "#     'desc_coding': ['variable_description', 'units', 'variable_coding_counts_distribution'],\n",
    "#     'desc_units_coding': ['variable_description', 'units', 'variable_coding_counts_distribution']\n",
    "# }\n",
    "# mult_doc_cols_inputs = {\"desc\": ['variable_description']}\n",
    "# input_dir = \"/Laura/tiff_laura_shared/\"\n",
    "# ref_file_diff = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HF Clin Trials\n",
    "# input_data_type = \"HF_clin_trials_biolincc_NLP\"\n",
    "# ref_id_col = 'var_doc_id'\n",
    "# doc_cols_inputs = {'desc': ['variable_description']}\n",
    "# mult_doc_cols_inputs = {\"desc\": ['variable_description']}\n",
    "# input_dir = \"/Laura/tiff_laura_shared/\"\n",
    "# ref_file_diff = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both HF Clin Trials and Obs Heart Studies\n",
    "#input_data_type = \"trials_studies_NLP\"\n",
    "#ref_id_col = 'var_doc_id'\n",
    "#doc_cols_inputs = {'desc': ['variable_description']}\n",
    "#mult_doc_cols_inputs = {\"desc\": ['variable_description']}\n",
    "#input_dir = \"/Laura/tiff_laura_shared/\"\n",
    "#ref_file_diff = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both SNOMED and Obs Heart Studies\n",
    "input_data_type = \"obs_heart_studies_dbGaP_NLP_SNOMED_terms\"\n",
    "ref_id_col = 'dbGaP_studyID_datasetID_varID'\n",
    "doc_cols_inputs = {'desc': ['variable_description']}\n",
    "mult_doc_cols_inputs = {\"desc\": ['variable_description']}\n",
    "input_dir = \"/Laura/automatic-variable-mapping/SNOMED-concepts/output/\"\n",
    "man_file = input_dir + \"manual_concept_var_mappings_\" + \"obs_heart_studies_dbGaP_NLP\" + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = input_dir + \"var_doc_\" + input_data_type + \".csv\"\n",
    "man_file = input_dir + \"manual_concept_var_mappings_\" + input_data_type + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/data/automatic-variable-mapping-results-2/\"\n",
    "out_prefix = \"var_txt_sim_scores\"\n",
    "num_cpus = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Laura/automatic-variable-mapping/SNOMED-concepts/output/var_doc_obs_heart_studies_dbGaP_NLP_SNOMED_terms.csv\n",
      "/Laura/automatic-variable-mapping/SNOMED-concepts/output/manual_concept_var_mappings_obs_heart_studies_dbGaP_NLP_SNOMED_terms.csv\n"
     ]
    }
   ],
   "source": [
    "print data_file\n",
    "print man_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study</th>\n",
       "      <th>cohort_dbGaP</th>\n",
       "      <th>dbGaP_studyID_datasetID</th>\n",
       "      <th>dbGaP_dataset_label</th>\n",
       "      <th>concept</th>\n",
       "      <th>data_desc</th>\n",
       "      <th>varID</th>\n",
       "      <th>var_desc</th>\n",
       "      <th>units</th>\n",
       "      <th>var_coding_counts_distribution</th>\n",
       "      <th>var_doc_id</th>\n",
       "      <th>concept_id</th>\n",
       "      <th>dbGaP_studyID_datasetID_varID</th>\n",
       "      <th>var_coding_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>Education</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF5</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=4884; nulls=195; HIGH SCHOOL GRADUATE=5:coun...</td>\n",
       "      <td>FHS1var2</td>\n",
       "      <td>education</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF5</td>\n",
       "      <td>FIFTH, SIXTH OR SEVENTH GRADE; NONE; POST GRAD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>number of pregnancies</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF20</td>\n",
       "      <td>NUMBER OF PREGNANCIES, EXAM 1</td>\n",
       "      <td>NUMBER OF PREGNANCIES</td>\n",
       "      <td>n=2122; nulls=17; mean=2.82; sd=1.353; median=...</td>\n",
       "      <td>FHS1var16</td>\n",
       "      <td>pregnancies</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF20</td>\n",
       "      <td>MAN, SINGLE WOMAN, OR NO PREGNANCIES FOR NON-S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>shareid</td>\n",
       "      <td>UNIQUE PARTICIPANT ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5079; nulls=0</td>\n",
       "      <td>FHS1var558</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000007.v26.pht000009.v2.shareid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000010.v3</td>\n",
       "      <td>ex0_8s</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 8</td>\n",
       "      <td>shareid</td>\n",
       "      <td>UNIQUE PARTICIPANT ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=3909; nulls=0</td>\n",
       "      <td>FHS2var151</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000007.v26.pht000010.v3.shareid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Marital Status</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB8</td>\n",
       "      <td>MARTIAL STATUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=3712; nulls=0; MARRIED=2:count=2847; WIDOWED...</td>\n",
       "      <td>FHS3var1</td>\n",
       "      <td>maritalStatus</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB8</td>\n",
       "      <td>MARRIED; SEPARATED; SINGLE; WIDOWED; DIVORCED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB18</td>\n",
       "      <td>BLOOD PRESSURE: SYSTOLIC, TAKEN BY NURSE</td>\n",
       "      <td>MM HG</td>\n",
       "      <td>n=3698; nulls=14; mean=138.7; sd=22.16; median...</td>\n",
       "      <td>FHS3var8</td>\n",
       "      <td>SBP</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB19</td>\n",
       "      <td>BLOOD PRESSURE: DIASTOLIC, TAKEN BY NURSE</td>\n",
       "      <td>MM HG</td>\n",
       "      <td>n=3699; nulls=13; mean=85.64; sd=11.88; median...</td>\n",
       "      <td>FHS3var9</td>\n",
       "      <td>DBP</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB20</td>\n",
       "      <td>BLOOD PRESSURE: SYSTOLIC, PHYSICIAN'S FIRST RE...</td>\n",
       "      <td>MM HG</td>\n",
       "      <td>n=3708; nulls=4; mean=140.1; sd=23.46; median=...</td>\n",
       "      <td>FHS3var10</td>\n",
       "      <td>SBP</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB21</td>\n",
       "      <td>BLOOD PRESSURE: DIASTOLIC, PHYSICIAN'S FIRST R...</td>\n",
       "      <td>MM HG</td>\n",
       "      <td>n=3705; nulls=7; mean=82.19; sd=11.59; median=...</td>\n",
       "      <td>FHS3var11</td>\n",
       "      <td>DBP</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB22</td>\n",
       "      <td>BLOOD PRESSURE: SYSTOLIC, PHYSICIAN'S SECOND R...</td>\n",
       "      <td>MM HG</td>\n",
       "      <td>n=3651; nulls=61; mean=139.1; sd=23.49; median...</td>\n",
       "      <td>FHS3var12</td>\n",
       "      <td>SBP</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB23</td>\n",
       "      <td>BLOOD PRESSURE: DIASTOLIC, PHYSICIAN'S SECOND ...</td>\n",
       "      <td>MM HG</td>\n",
       "      <td>n=3650; nulls=62; mean=81.81; sd=11.61; median...</td>\n",
       "      <td>FHS3var13</td>\n",
       "      <td>DBP</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>cholesterol mg/dL</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB28</td>\n",
       "      <td>BLOOD ANALYSIS:  CHOLESTEROL, TOTAL</td>\n",
       "      <td>MG/100ML</td>\n",
       "      <td>n=3581; nulls=131; mean=241.5; sd=45.62; media...</td>\n",
       "      <td>FHS3var18</td>\n",
       "      <td>cholesterol_mg_dL</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>LDL cholesterol mg/dL</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB29</td>\n",
       "      <td>BLOOD ANALYSIS:  CHOLESTEROL, BETA</td>\n",
       "      <td>MG/100 ML</td>\n",
       "      <td>n=3548; nulls=164; mean=193.3; sd=44.41; media...</td>\n",
       "      <td>FHS3var19</td>\n",
       "      <td>LDLmg_dL</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>HDL cholesterol mg/dL</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB30</td>\n",
       "      <td>BLOOD ANALYSIS:  CHOLESTEROL, ALPHA</td>\n",
       "      <td>MG/100 ML</td>\n",
       "      <td>n=3547; nulls=165; mean=48.12; sd=14.52; media...</td>\n",
       "      <td>FHS3var20</td>\n",
       "      <td>HDLmg_dL</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Current Smoking Status (smoker in last year)</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB83</td>\n",
       "      <td>INTERIM HISTORY OF SMOKING:  SMOKED AT LEAST O...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=3712; nulls=0; NO=2000:count=2006; YES=1:cou...</td>\n",
       "      <td>FHS3var68</td>\n",
       "      <td>smoke</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB83</td>\n",
       "      <td>NO; YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>systolic murmur (grade)</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB146</td>\n",
       "      <td>HEART EXAMINATION:  ANY SIGNIFICANT SYSTOLIC M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=3708; nulls=4; NO=0:count=3553; YES, DEFINIT...</td>\n",
       "      <td>FHS3var114</td>\n",
       "      <td>sysMurmur</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB146</td>\n",
       "      <td>YES, MAYBE; NO; UNKNOWN; YES, DEFINITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>diastolic murmur (binary)</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB148</td>\n",
       "      <td>HEART EXAMINATION:  DIASTOLIC MURMURS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=3702; nulls=10; NONE=0:count=3653; AORTIC=2:...</td>\n",
       "      <td>FHS3var116</td>\n",
       "      <td>diaMurbinary</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB148</td>\n",
       "      <td>AORTIC; NONE; UNKNOWN; MITRAL; BOTH; OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB181</td>\n",
       "      <td>ECG: VENTRICULAR RATE</td>\n",
       "      <td>PER MINUTE</td>\n",
       "      <td>n=3710; nulls=2; mean=78.05; sd=12.82; median=...</td>\n",
       "      <td>FHS3var142</td>\n",
       "      <td>HR</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB181</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>PR Interval</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB182</td>\n",
       "      <td>ECG: P-R INTERVAL</td>\n",
       "      <td>HUNDREDTHS OF SECONDS</td>\n",
       "      <td>n=3677; nulls=2; mean=15.79; sd=2.176; median=...</td>\n",
       "      <td>FHS3var143</td>\n",
       "      <td>PR</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB182</td>\n",
       "      <td>ATRIAL FIBRILLATION; ECG NOT TAKEN; INDETERMINATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Left Ventricular Hypertrophy</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB185</td>\n",
       "      <td>ECG:  LEFT VENTRICULAR HYPERTROPHY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=3710; nulls=2; NO=0:count=3555; YES, MAYBE=2...</td>\n",
       "      <td>FHS3var146</td>\n",
       "      <td>LVH</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB185</td>\n",
       "      <td>YES, MAYBE; NO; ECG NOT TAKEN; YES, DEFINITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Atrial Fibrillation Status (A-fib/flutter)</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB191</td>\n",
       "      <td>ECG:  ATRIAL FIBRILLATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=3710; nulls=2; NO=0:count=3680; YES=1:count=...</td>\n",
       "      <td>FHS3var152</td>\n",
       "      <td>prevAF</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB191</td>\n",
       "      <td>NO; ECG NOT TAKEN; YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Atrial Fibrillation Status (A-fib/flutter)</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB192</td>\n",
       "      <td>ECG:  ATRIAL FLUTTER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=3710; nulls=2; NO=0:count=3709; YES=1:count=...</td>\n",
       "      <td>FHS3var153</td>\n",
       "      <td>prevAF</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB192</td>\n",
       "      <td>NO; ECG NOT TAKEN; YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>Hypertension Medication</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>FB221</td>\n",
       "      <td>CLINICAL DIAGNOSTIC IMPRESSION:  UNDER TREATME...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=3711; nulls=1; NO=0:count=3214; YES, DEFINIT...</td>\n",
       "      <td>FHS3var159</td>\n",
       "      <td>HTNmed</td>\n",
       "      <td>phs000007.v26.pht000011.v3.FB221</td>\n",
       "      <td>YES, MAYBE; NO; UNKNOWN; YES, DEFINITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000011.v3</td>\n",
       "      <td>ex0_9s</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 9</td>\n",
       "      <td>shareid</td>\n",
       "      <td>UNIQUE PARTICIPANT ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=3712; nulls=0</td>\n",
       "      <td>FHS3var176</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000007.v26.pht000011.v3.shareid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000012.v3</td>\n",
       "      <td>ex0_10s</td>\n",
       "      <td>cholesterol mg/dL</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 10</td>\n",
       "      <td>FC22</td>\n",
       "      <td>BLOOD ANALYSIS: TOTAL CHOLESTEROL (MG/100 ML)</td>\n",
       "      <td>MG/100ML</td>\n",
       "      <td>n=2626; nulls=847; mean=235; sd=43.76; median=...</td>\n",
       "      <td>FHS4var17</td>\n",
       "      <td>cholesterol_mg_dL</td>\n",
       "      <td>phs000007.v26.pht000012.v3.FC22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000012.v3</td>\n",
       "      <td>ex0_10s</td>\n",
       "      <td>LDL cholesterol mg/dL</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 10</td>\n",
       "      <td>FC23</td>\n",
       "      <td>BLOOD ANALYSIS: BETA CHOLESTEROL (MG/100 ML)</td>\n",
       "      <td>MG/100ML</td>\n",
       "      <td>n=2604; nulls=869; mean=186.5; sd=43.17; media...</td>\n",
       "      <td>FHS4var18</td>\n",
       "      <td>LDLmg_dL</td>\n",
       "      <td>phs000007.v26.pht000012.v3.FC23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000012.v3</td>\n",
       "      <td>ex0_10s</td>\n",
       "      <td>HDL cholesterol mg/dL</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 10</td>\n",
       "      <td>FC24</td>\n",
       "      <td>BLOOD ANALYSIS: ALPHA CHOLESTEROL (MG/100 ML)</td>\n",
       "      <td>MG/100ML</td>\n",
       "      <td>n=2604; nulls=869; mean=48.49; sd=16.17; media...</td>\n",
       "      <td>FHS4var19</td>\n",
       "      <td>HDLmg_dL</td>\n",
       "      <td>phs000007.v26.pht000012.v3.FC24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000012.v3</td>\n",
       "      <td>ex0_10s</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 10</td>\n",
       "      <td>shareid</td>\n",
       "      <td>UNIQUE PARTICIPANT ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=3473; nulls=0</td>\n",
       "      <td>FHS4var196</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000007.v26.pht000012.v3.shareid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000013.v3</td>\n",
       "      <td>ex0_11s</td>\n",
       "      <td>cholesterol mg/dL</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 11</td>\n",
       "      <td>FD36</td>\n",
       "      <td>BLOOD ANALYSIS, FASTING: TOTAL CHOLESTEROL SER...</td>\n",
       "      <td>MG/100 ML</td>\n",
       "      <td>n=1309; nulls=1543; mean=234.3; sd=43.16; medi...</td>\n",
       "      <td>FHS5var22</td>\n",
       "      <td>cholesterol_mg_dL</td>\n",
       "      <td>phs000007.v26.pht000013.v3.FD36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FHS</td>\n",
       "      <td>Original</td>\n",
       "      <td>phs000007.v26.pht000013.v3</td>\n",
       "      <td>ex0_11s</td>\n",
       "      <td>HDL cholesterol mg/dL</td>\n",
       "      <td>Clinic Exam, Original Cohort Exam 11</td>\n",
       "      <td>FD37</td>\n",
       "      <td>BLOOD ANALYSIS, FASTING: ALPHA CHOLESTEROL (SE...</td>\n",
       "      <td>MG/100 ML</td>\n",
       "      <td>n=1309; nulls=1543; mean=51.93; sd=15.81; medi...</td>\n",
       "      <td>FHS5var23</td>\n",
       "      <td>HDLmg_dL</td>\n",
       "      <td>phs000007.v26.pht000013.v3.FD37</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht003479.v1</td>\n",
       "      <td>MESA_AncilMesaGGT</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>MESA Ancillary Study Dataset: Gamma-Glutamyltr...</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=6412; nulls=0</td>\n",
       "      <td>MESA74var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht003479.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht003604.v2</td>\n",
       "      <td>MESA_AncilMesaNeighborScalesExam5</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=4382; nulls=0</td>\n",
       "      <td>MESA75var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht003604.v2.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht003605.v1</td>\n",
       "      <td>MESA_AncilMesaNeighborFoodExam1</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>MESA Neighborhood Ancillary Study Exam 1 datas...</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5853; nulls=0</td>\n",
       "      <td>MESA76var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht003605.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht003606.v1</td>\n",
       "      <td>MESA_AncilMesaNeighborFoodExam2</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>MESA Neighborhood Ancillary Study Exam 2 datas...</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5756; nulls=0</td>\n",
       "      <td>MESA77var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht003606.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht003607.v1</td>\n",
       "      <td>MESA_AncilMesaNeighborFoodExam3</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>MESA Neighborhood Ancillary Study Exam 3 datas...</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5601; nulls=0</td>\n",
       "      <td>MESA78var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht003607.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht003608.v1</td>\n",
       "      <td>MESA_AncilMesaNeighborFoodExam4</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>MESA Neighborhood Ancillary Study Exam 4 datas...</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5393; nulls=0</td>\n",
       "      <td>MESA79var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht003608.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht003609.v1</td>\n",
       "      <td>MESA_AncilMesaNeighborFoodExam5</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>MESA Neighborhood Ancillary Study Exam 5 datas...</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=4382; nulls=0</td>\n",
       "      <td>MESA80var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht003609.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht003610.v1</td>\n",
       "      <td>MESA_AncilMesaNeighborScalesSodiumExam1</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>MESA Neighborhood Ancillary Study DASH Diet Sc...</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARe ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5631; nulls=0</td>\n",
       "      <td>MESA81var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht003610.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht003659.v1</td>\n",
       "      <td>MESA_TimeToDiabetes</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>MESA Time to Diabetes Dataset: This dataset co...</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=6429; nulls=0</td>\n",
       "      <td>MESA82var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht003659.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004316.v1</td>\n",
       "      <td>MESA_ancilmesalungvariant</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=3385; nulls=0</td>\n",
       "      <td>MESA83var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht004316.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004317.v1</td>\n",
       "      <td>MESA_exam5dietnutrients</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=4267; nulls=0</td>\n",
       "      <td>MESA84var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht004317.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004318.v1</td>\n",
       "      <td>MESA_ancilmesaurinesexhormone</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=1690; nulls=0</td>\n",
       "      <td>MESA85var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht004318.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004319.v1</td>\n",
       "      <td>MESA_AncilMesaEpigenomicCBC</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=2800; nulls=0</td>\n",
       "      <td>MESA86var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht004319.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004320.v1</td>\n",
       "      <td>MESA_AncilMesaGlycA</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=6420; nulls=0</td>\n",
       "      <td>MESA87var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht004320.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004321.v1</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam1</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5853; nulls=0</td>\n",
       "      <td>MESA88var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht004321.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004322.v1</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam2</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5756; nulls=0</td>\n",
       "      <td>MESA89var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht004322.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004323.v1</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam3</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5601; nulls=0</td>\n",
       "      <td>MESA90var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht004323.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004324.v1</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam4</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5393; nulls=0</td>\n",
       "      <td>MESA91var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht004324.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004325.v1</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam5</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=4382; nulls=0</td>\n",
       "      <td>MESA92var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht004325.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>unique Participant Identifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=950; nulls=0</td>\n",
       "      <td>MESA93var1</td>\n",
       "      <td>ParticipantID</td>\n",
       "      <td>phs000209.v13.pht004326.v1.sidno</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>educ1</td>\n",
       "      <td>EDUCATION: HIGHEST LEVEL COMPLETED AT BASELINE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=950; nulls=0; COMPLETED HIGH SCHOOL/GED=3:co...</td>\n",
       "      <td>MESA93var2</td>\n",
       "      <td>education</td>\n",
       "      <td>phs000209.v13.pht004326.v1.educ1</td>\n",
       "      <td>NO SCHOOLING; GRADES 1-8; GRADES 9-11; COMPLET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>Gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gender1</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=950; nulls=0; FEMALE=0:count=494; MALE=1:cou...</td>\n",
       "      <td>MESA93var5</td>\n",
       "      <td>gender</td>\n",
       "      <td>phs000209.v13.pht004326.v1.gender1</td>\n",
       "      <td>FEMALE; MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>BMI (kg/m^2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bmisc</td>\n",
       "      <td>BODY MASS INDEX (KG/M^2) AT MESA STRESS EXAM</td>\n",
       "      <td>KG/M^2</td>\n",
       "      <td>n=949; nulls=1; mean=29.03; sd=5.652; median=2...</td>\n",
       "      <td>MESA93var8</td>\n",
       "      <td>BMI</td>\n",
       "      <td>phs000209.v13.pht004326.v1.bmisc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht001118.v8</td>\n",
       "      <td>MESA_Exam2Main</td>\n",
       "      <td>Race/Ethnicity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>othhisp1</td>\n",
       "      <td>OTHER HISPANIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5889; nulls=540; NO=0:count=5698; YES=1:coun...</td>\n",
       "      <td>MESA9var7</td>\n",
       "      <td>race_ethnicity</td>\n",
       "      <td>phs000209.v13.pht001118.v8.othhisp1</td>\n",
       "      <td>NO; YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht001119.v8</td>\n",
       "      <td>MESA_Exam3Main</td>\n",
       "      <td>Race/Ethnicity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>othhisp1</td>\n",
       "      <td>OTHER HISPANIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5616; nulls=813; NO=0:count=5439; YES=1:coun...</td>\n",
       "      <td>MESA10var7</td>\n",
       "      <td>race_ethnicity</td>\n",
       "      <td>phs000209.v13.pht001119.v8.othhisp1</td>\n",
       "      <td>NO; YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht001120.v10</td>\n",
       "      <td>MESA_Exam4Main</td>\n",
       "      <td>Race/Ethnicity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>othhisp1</td>\n",
       "      <td>OTHER HISPANIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=5494; nulls=935; NO=0:count=5330; YES=1:coun...</td>\n",
       "      <td>MESA11var7</td>\n",
       "      <td>race_ethnicity</td>\n",
       "      <td>phs000209.v13.pht001120.v10.othhisp1</td>\n",
       "      <td>NO; YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht001121.v3</td>\n",
       "      <td>MESA_FamilyExamMain</td>\n",
       "      <td>Race/Ethnicity</td>\n",
       "      <td>MESA Family Exam Main Dataset: The MESA Family...</td>\n",
       "      <td>racefc</td>\n",
       "      <td>RACE AND ETHNICITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=1616; nulls=0; BLACK, AFRICAN-AMERICAN=3:cou...</td>\n",
       "      <td>MESA12var5</td>\n",
       "      <td>race_ethnicity</td>\n",
       "      <td>phs000209.v13.pht001121.v3.racefc</td>\n",
       "      <td>WHITE, CAUCASIAN; CHINESE AMERICAN; BLACK, AFR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht003087.v1</td>\n",
       "      <td>MESA_AncilMesaCTRead185</td>\n",
       "      <td>Race/Ethnicity</td>\n",
       "      <td>MESA Lung CT Read 185: Lung CT reads for 185 c...</td>\n",
       "      <td>race</td>\n",
       "      <td>RACE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=185; nulls=0; mean=3.514; sd=0.5012; median=...</td>\n",
       "      <td>MESA58var83</td>\n",
       "      <td>race_ethnicity</td>\n",
       "      <td>phs000209.v13.pht003087.v1.race</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht003087.v1</td>\n",
       "      <td>MESA_AncilMesaCTRead185</td>\n",
       "      <td>Race/Ethnicity</td>\n",
       "      <td>MESA Lung CT Read 185: Lung CT reads for 185 c...</td>\n",
       "      <td>racefc</td>\n",
       "      <td>FAMILY COHORT: RACE AND ETHNICITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=32; nulls=153; BLACK, AFRICAN-AMERICAN=3:cou...</td>\n",
       "      <td>MESA58var148</td>\n",
       "      <td>race_ethnicity</td>\n",
       "      <td>phs000209.v13.pht003087.v1.racefc</td>\n",
       "      <td>WHITE, CAUCASIAN; CHINESE AMERICAN; BLACK, AFR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>MESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>Race/Ethnicity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>race1c</td>\n",
       "      <td>RACE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n=950; nulls=0; HISPANIC=4:count=515; BLACK, A...</td>\n",
       "      <td>MESA93var4</td>\n",
       "      <td>race_ethnicity</td>\n",
       "      <td>phs000209.v13.pht004326.v1.race1c</td>\n",
       "      <td>WHITE, CAUCASIAN; CHINESE AMERICAN; BLACK, AFR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1709 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     study cohort_dbGaP      dbGaP_studyID_datasetID  \\\n",
       "0      FHS     Original   phs000007.v26.pht000009.v2   \n",
       "1      FHS     Original   phs000007.v26.pht000009.v2   \n",
       "2      FHS     Original   phs000007.v26.pht000009.v2   \n",
       "3      FHS     Original   phs000007.v26.pht000010.v3   \n",
       "4      FHS     Original   phs000007.v26.pht000011.v3   \n",
       "5      FHS     Original   phs000007.v26.pht000011.v3   \n",
       "6      FHS     Original   phs000007.v26.pht000011.v3   \n",
       "7      FHS     Original   phs000007.v26.pht000011.v3   \n",
       "8      FHS     Original   phs000007.v26.pht000011.v3   \n",
       "9      FHS     Original   phs000007.v26.pht000011.v3   \n",
       "10     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "11     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "12     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "13     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "14     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "15     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "16     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "17     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "18     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "19     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "20     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "21     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "22     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "23     FHS     Original   phs000007.v26.pht000011.v3   \n",
       "24     FHS     Original   phs000007.v26.pht000012.v3   \n",
       "25     FHS     Original   phs000007.v26.pht000012.v3   \n",
       "26     FHS     Original   phs000007.v26.pht000012.v3   \n",
       "27     FHS     Original   phs000007.v26.pht000012.v3   \n",
       "28     FHS     Original   phs000007.v26.pht000013.v3   \n",
       "29     FHS     Original   phs000007.v26.pht000013.v3   \n",
       "...    ...          ...                          ...   \n",
       "1679  MESA          NaN   phs000209.v13.pht003479.v1   \n",
       "1680  MESA          NaN   phs000209.v13.pht003604.v2   \n",
       "1681  MESA          NaN   phs000209.v13.pht003605.v1   \n",
       "1682  MESA          NaN   phs000209.v13.pht003606.v1   \n",
       "1683  MESA          NaN   phs000209.v13.pht003607.v1   \n",
       "1684  MESA          NaN   phs000209.v13.pht003608.v1   \n",
       "1685  MESA          NaN   phs000209.v13.pht003609.v1   \n",
       "1686  MESA          NaN   phs000209.v13.pht003610.v1   \n",
       "1687  MESA          NaN   phs000209.v13.pht003659.v1   \n",
       "1688  MESA          NaN   phs000209.v13.pht004316.v1   \n",
       "1689  MESA          NaN   phs000209.v13.pht004317.v1   \n",
       "1690  MESA          NaN   phs000209.v13.pht004318.v1   \n",
       "1691  MESA          NaN   phs000209.v13.pht004319.v1   \n",
       "1692  MESA          NaN   phs000209.v13.pht004320.v1   \n",
       "1693  MESA          NaN   phs000209.v13.pht004321.v1   \n",
       "1694  MESA          NaN   phs000209.v13.pht004322.v1   \n",
       "1695  MESA          NaN   phs000209.v13.pht004323.v1   \n",
       "1696  MESA          NaN   phs000209.v13.pht004324.v1   \n",
       "1697  MESA          NaN   phs000209.v13.pht004325.v1   \n",
       "1698  MESA          NaN   phs000209.v13.pht004326.v1   \n",
       "1699  MESA          NaN   phs000209.v13.pht004326.v1   \n",
       "1700  MESA          NaN   phs000209.v13.pht004326.v1   \n",
       "1701  MESA          NaN   phs000209.v13.pht004326.v1   \n",
       "1702  MESA          NaN   phs000209.v13.pht001118.v8   \n",
       "1703  MESA          NaN   phs000209.v13.pht001119.v8   \n",
       "1704  MESA          NaN  phs000209.v13.pht001120.v10   \n",
       "1705  MESA          NaN   phs000209.v13.pht001121.v3   \n",
       "1706  MESA          NaN   phs000209.v13.pht003087.v1   \n",
       "1707  MESA          NaN   phs000209.v13.pht003087.v1   \n",
       "1708  MESA          NaN   phs000209.v13.pht004326.v1   \n",
       "\n",
       "                          dbGaP_dataset_label  \\\n",
       "0                                      ex0_7s   \n",
       "1                                      ex0_7s   \n",
       "2                                      ex0_7s   \n",
       "3                                      ex0_8s   \n",
       "4                                      ex0_9s   \n",
       "5                                      ex0_9s   \n",
       "6                                      ex0_9s   \n",
       "7                                      ex0_9s   \n",
       "8                                      ex0_9s   \n",
       "9                                      ex0_9s   \n",
       "10                                     ex0_9s   \n",
       "11                                     ex0_9s   \n",
       "12                                     ex0_9s   \n",
       "13                                     ex0_9s   \n",
       "14                                     ex0_9s   \n",
       "15                                     ex0_9s   \n",
       "16                                     ex0_9s   \n",
       "17                                     ex0_9s   \n",
       "18                                     ex0_9s   \n",
       "19                                     ex0_9s   \n",
       "20                                     ex0_9s   \n",
       "21                                     ex0_9s   \n",
       "22                                     ex0_9s   \n",
       "23                                     ex0_9s   \n",
       "24                                    ex0_10s   \n",
       "25                                    ex0_10s   \n",
       "26                                    ex0_10s   \n",
       "27                                    ex0_10s   \n",
       "28                                    ex0_11s   \n",
       "29                                    ex0_11s   \n",
       "...                                       ...   \n",
       "1679                        MESA_AncilMesaGGT   \n",
       "1680        MESA_AncilMesaNeighborScalesExam5   \n",
       "1681          MESA_AncilMesaNeighborFoodExam1   \n",
       "1682          MESA_AncilMesaNeighborFoodExam2   \n",
       "1683          MESA_AncilMesaNeighborFoodExam3   \n",
       "1684          MESA_AncilMesaNeighborFoodExam4   \n",
       "1685          MESA_AncilMesaNeighborFoodExam5   \n",
       "1686  MESA_AncilMesaNeighborScalesSodiumExam1   \n",
       "1687                      MESA_TimeToDiabetes   \n",
       "1688                MESA_ancilmesalungvariant   \n",
       "1689                  MESA_exam5dietnutrients   \n",
       "1690            MESA_ancilmesaurinesexhormone   \n",
       "1691              MESA_AncilMesaEpigenomicCBC   \n",
       "1692                      MESA_AncilMesaGlycA   \n",
       "1693           MESA_AncilMesaNeighborSESExam1   \n",
       "1694           MESA_AncilMesaNeighborSESExam2   \n",
       "1695           MESA_AncilMesaNeighborSESExam3   \n",
       "1696           MESA_AncilMesaNeighborSESExam4   \n",
       "1697           MESA_AncilMesaNeighborSESExam5   \n",
       "1698                MESA_AncilMesaStressWave1   \n",
       "1699                MESA_AncilMesaStressWave1   \n",
       "1700                MESA_AncilMesaStressWave1   \n",
       "1701                MESA_AncilMesaStressWave1   \n",
       "1702                           MESA_Exam2Main   \n",
       "1703                           MESA_Exam3Main   \n",
       "1704                           MESA_Exam4Main   \n",
       "1705                      MESA_FamilyExamMain   \n",
       "1706                  MESA_AncilMesaCTRead185   \n",
       "1707                  MESA_AncilMesaCTRead185   \n",
       "1708                MESA_AncilMesaStressWave1   \n",
       "\n",
       "                                           concept  \\\n",
       "0                                        Education   \n",
       "1                            number of pregnancies   \n",
       "2                    unique Participant Identifier   \n",
       "3                    unique Participant Identifier   \n",
       "4                                   Marital Status   \n",
       "5                   Systolic Blood Pressure (mmHg)   \n",
       "6                  Diastolic Blood Pressure (mmHg)   \n",
       "7                   Systolic Blood Pressure (mmHg)   \n",
       "8                  Diastolic Blood Pressure (mmHg)   \n",
       "9                   Systolic Blood Pressure (mmHg)   \n",
       "10                 Diastolic Blood Pressure (mmHg)   \n",
       "11                               cholesterol mg/dL   \n",
       "12                           LDL cholesterol mg/dL   \n",
       "13                           HDL cholesterol mg/dL   \n",
       "14    Current Smoking Status (smoker in last year)   \n",
       "15                         systolic murmur (grade)   \n",
       "16                       diastolic murmur (binary)   \n",
       "17                          Heart Rate (beats/min)   \n",
       "18                                     PR Interval   \n",
       "19                    Left Ventricular Hypertrophy   \n",
       "20      Atrial Fibrillation Status (A-fib/flutter)   \n",
       "21      Atrial Fibrillation Status (A-fib/flutter)   \n",
       "22                         Hypertension Medication   \n",
       "23                   unique Participant Identifier   \n",
       "24                               cholesterol mg/dL   \n",
       "25                           LDL cholesterol mg/dL   \n",
       "26                           HDL cholesterol mg/dL   \n",
       "27                   unique Participant Identifier   \n",
       "28                               cholesterol mg/dL   \n",
       "29                           HDL cholesterol mg/dL   \n",
       "...                                            ...   \n",
       "1679                 unique Participant Identifier   \n",
       "1680                 unique Participant Identifier   \n",
       "1681                 unique Participant Identifier   \n",
       "1682                 unique Participant Identifier   \n",
       "1683                 unique Participant Identifier   \n",
       "1684                 unique Participant Identifier   \n",
       "1685                 unique Participant Identifier   \n",
       "1686                 unique Participant Identifier   \n",
       "1687                 unique Participant Identifier   \n",
       "1688                 unique Participant Identifier   \n",
       "1689                 unique Participant Identifier   \n",
       "1690                 unique Participant Identifier   \n",
       "1691                 unique Participant Identifier   \n",
       "1692                 unique Participant Identifier   \n",
       "1693                 unique Participant Identifier   \n",
       "1694                 unique Participant Identifier   \n",
       "1695                 unique Participant Identifier   \n",
       "1696                 unique Participant Identifier   \n",
       "1697                 unique Participant Identifier   \n",
       "1698                 unique Participant Identifier   \n",
       "1699                                     Education   \n",
       "1700                                        Gender   \n",
       "1701                                  BMI (kg/m^2)   \n",
       "1702                                Race/Ethnicity   \n",
       "1703                                Race/Ethnicity   \n",
       "1704                                Race/Ethnicity   \n",
       "1705                                Race/Ethnicity   \n",
       "1706                                Race/Ethnicity   \n",
       "1707                                Race/Ethnicity   \n",
       "1708                                Race/Ethnicity   \n",
       "\n",
       "                                              data_desc     varID  \\\n",
       "0              Clinic Exam, Original Cohort Exams 1 - 7       MF5   \n",
       "1              Clinic Exam, Original Cohort Exams 1 - 7      MF20   \n",
       "2              Clinic Exam, Original Cohort Exams 1 - 7   shareid   \n",
       "3                   Clinic Exam, Original Cohort Exam 8   shareid   \n",
       "4                   Clinic Exam, Original Cohort Exam 9       FB8   \n",
       "5                   Clinic Exam, Original Cohort Exam 9      FB18   \n",
       "6                   Clinic Exam, Original Cohort Exam 9      FB19   \n",
       "7                   Clinic Exam, Original Cohort Exam 9      FB20   \n",
       "8                   Clinic Exam, Original Cohort Exam 9      FB21   \n",
       "9                   Clinic Exam, Original Cohort Exam 9      FB22   \n",
       "10                  Clinic Exam, Original Cohort Exam 9      FB23   \n",
       "11                  Clinic Exam, Original Cohort Exam 9      FB28   \n",
       "12                  Clinic Exam, Original Cohort Exam 9      FB29   \n",
       "13                  Clinic Exam, Original Cohort Exam 9      FB30   \n",
       "14                  Clinic Exam, Original Cohort Exam 9      FB83   \n",
       "15                  Clinic Exam, Original Cohort Exam 9     FB146   \n",
       "16                  Clinic Exam, Original Cohort Exam 9     FB148   \n",
       "17                  Clinic Exam, Original Cohort Exam 9     FB181   \n",
       "18                  Clinic Exam, Original Cohort Exam 9     FB182   \n",
       "19                  Clinic Exam, Original Cohort Exam 9     FB185   \n",
       "20                  Clinic Exam, Original Cohort Exam 9     FB191   \n",
       "21                  Clinic Exam, Original Cohort Exam 9     FB192   \n",
       "22                  Clinic Exam, Original Cohort Exam 9     FB221   \n",
       "23                  Clinic Exam, Original Cohort Exam 9   shareid   \n",
       "24                 Clinic Exam, Original Cohort Exam 10      FC22   \n",
       "25                 Clinic Exam, Original Cohort Exam 10      FC23   \n",
       "26                 Clinic Exam, Original Cohort Exam 10      FC24   \n",
       "27                 Clinic Exam, Original Cohort Exam 10   shareid   \n",
       "28                 Clinic Exam, Original Cohort Exam 11      FD36   \n",
       "29                 Clinic Exam, Original Cohort Exam 11      FD37   \n",
       "...                                                 ...       ...   \n",
       "1679  MESA Ancillary Study Dataset: Gamma-Glutamyltr...     sidno   \n",
       "1680                                                NaN     sidno   \n",
       "1681  MESA Neighborhood Ancillary Study Exam 1 datas...     sidno   \n",
       "1682  MESA Neighborhood Ancillary Study Exam 2 datas...     sidno   \n",
       "1683  MESA Neighborhood Ancillary Study Exam 3 datas...     sidno   \n",
       "1684  MESA Neighborhood Ancillary Study Exam 4 datas...     sidno   \n",
       "1685  MESA Neighborhood Ancillary Study Exam 5 datas...     sidno   \n",
       "1686  MESA Neighborhood Ancillary Study DASH Diet Sc...     sidno   \n",
       "1687  MESA Time to Diabetes Dataset: This dataset co...     sidno   \n",
       "1688                                                NaN     sidno   \n",
       "1689                                                NaN     sidno   \n",
       "1690                                                NaN     sidno   \n",
       "1691                                                NaN     sidno   \n",
       "1692                                                NaN     sidno   \n",
       "1693                                                NaN     sidno   \n",
       "1694                                                NaN     sidno   \n",
       "1695                                                NaN     sidno   \n",
       "1696                                                NaN     sidno   \n",
       "1697                                                NaN     sidno   \n",
       "1698                                                NaN     sidno   \n",
       "1699                                                NaN     educ1   \n",
       "1700                                                NaN   gender1   \n",
       "1701                                                NaN     bmisc   \n",
       "1702                                                NaN  othhisp1   \n",
       "1703                                                NaN  othhisp1   \n",
       "1704                                                NaN  othhisp1   \n",
       "1705  MESA Family Exam Main Dataset: The MESA Family...    racefc   \n",
       "1706  MESA Lung CT Read 185: Lung CT reads for 185 c...      race   \n",
       "1707  MESA Lung CT Read 185: Lung CT reads for 185 c...    racefc   \n",
       "1708                                                NaN    race1c   \n",
       "\n",
       "                                               var_desc  \\\n",
       "0                                             EDUCATION   \n",
       "1                         NUMBER OF PREGNANCIES, EXAM 1   \n",
       "2                                 UNIQUE PARTICIPANT ID   \n",
       "3                                 UNIQUE PARTICIPANT ID   \n",
       "4                                        MARTIAL STATUS   \n",
       "5              BLOOD PRESSURE: SYSTOLIC, TAKEN BY NURSE   \n",
       "6             BLOOD PRESSURE: DIASTOLIC, TAKEN BY NURSE   \n",
       "7     BLOOD PRESSURE: SYSTOLIC, PHYSICIAN'S FIRST RE...   \n",
       "8     BLOOD PRESSURE: DIASTOLIC, PHYSICIAN'S FIRST R...   \n",
       "9     BLOOD PRESSURE: SYSTOLIC, PHYSICIAN'S SECOND R...   \n",
       "10    BLOOD PRESSURE: DIASTOLIC, PHYSICIAN'S SECOND ...   \n",
       "11                  BLOOD ANALYSIS:  CHOLESTEROL, TOTAL   \n",
       "12                   BLOOD ANALYSIS:  CHOLESTEROL, BETA   \n",
       "13                  BLOOD ANALYSIS:  CHOLESTEROL, ALPHA   \n",
       "14    INTERIM HISTORY OF SMOKING:  SMOKED AT LEAST O...   \n",
       "15    HEART EXAMINATION:  ANY SIGNIFICANT SYSTOLIC M...   \n",
       "16                HEART EXAMINATION:  DIASTOLIC MURMURS   \n",
       "17                                ECG: VENTRICULAR RATE   \n",
       "18                                    ECG: P-R INTERVAL   \n",
       "19                   ECG:  LEFT VENTRICULAR HYPERTROPHY   \n",
       "20                            ECG:  ATRIAL FIBRILLATION   \n",
       "21                                 ECG:  ATRIAL FLUTTER   \n",
       "22    CLINICAL DIAGNOSTIC IMPRESSION:  UNDER TREATME...   \n",
       "23                                UNIQUE PARTICIPANT ID   \n",
       "24        BLOOD ANALYSIS: TOTAL CHOLESTEROL (MG/100 ML)   \n",
       "25         BLOOD ANALYSIS: BETA CHOLESTEROL (MG/100 ML)   \n",
       "26        BLOOD ANALYSIS: ALPHA CHOLESTEROL (MG/100 ML)   \n",
       "27                                UNIQUE PARTICIPANT ID   \n",
       "28    BLOOD ANALYSIS, FASTING: TOTAL CHOLESTEROL SER...   \n",
       "29    BLOOD ANALYSIS, FASTING: ALPHA CHOLESTEROL (SE...   \n",
       "...                                                 ...   \n",
       "1679                                    SHARE ID NUMBER   \n",
       "1680                                    SHARE ID Number   \n",
       "1681                                    SHARE ID NUMBER   \n",
       "1682                                    SHARE ID NUMBER   \n",
       "1683                                    SHARE ID NUMBER   \n",
       "1684                                    SHARE ID NUMBER   \n",
       "1685                                    SHARE ID NUMBER   \n",
       "1686                                    SHARe ID Number   \n",
       "1687                                    SHARE ID NUMBER   \n",
       "1688                                    SHARE ID NUMBER   \n",
       "1689                                    SHARE ID NUMBER   \n",
       "1690                                    SHARE ID Number   \n",
       "1691                                    SHARE ID Number   \n",
       "1692                                    SHARE ID Number   \n",
       "1693                                    SHARE ID Number   \n",
       "1694                                    SHARE ID Number   \n",
       "1695                                    SHARE ID Number   \n",
       "1696                                    SHARE ID Number   \n",
       "1697                                    SHARE ID Number   \n",
       "1698                                    SHARE ID NUMBER   \n",
       "1699  EDUCATION: HIGHEST LEVEL COMPLETED AT BASELINE...   \n",
       "1700                                             GENDER   \n",
       "1701       BODY MASS INDEX (KG/M^2) AT MESA STRESS EXAM   \n",
       "1702                                     OTHER HISPANIC   \n",
       "1703                                     OTHER HISPANIC   \n",
       "1704                                     OTHER HISPANIC   \n",
       "1705                                 RACE AND ETHNICITY   \n",
       "1706                                               RACE   \n",
       "1707                  FAMILY COHORT: RACE AND ETHNICITY   \n",
       "1708                                               RACE   \n",
       "\n",
       "                      units  \\\n",
       "0                       NaN   \n",
       "1     NUMBER OF PREGNANCIES   \n",
       "2                       NaN   \n",
       "3                       NaN   \n",
       "4                       NaN   \n",
       "5                     MM HG   \n",
       "6                     MM HG   \n",
       "7                     MM HG   \n",
       "8                     MM HG   \n",
       "9                     MM HG   \n",
       "10                    MM HG   \n",
       "11                 MG/100ML   \n",
       "12                MG/100 ML   \n",
       "13                MG/100 ML   \n",
       "14                      NaN   \n",
       "15                      NaN   \n",
       "16                      NaN   \n",
       "17               PER MINUTE   \n",
       "18    HUNDREDTHS OF SECONDS   \n",
       "19                      NaN   \n",
       "20                      NaN   \n",
       "21                      NaN   \n",
       "22                      NaN   \n",
       "23                      NaN   \n",
       "24                 MG/100ML   \n",
       "25                 MG/100ML   \n",
       "26                 MG/100ML   \n",
       "27                      NaN   \n",
       "28                MG/100 ML   \n",
       "29                MG/100 ML   \n",
       "...                     ...   \n",
       "1679                    NaN   \n",
       "1680                    NaN   \n",
       "1681                    NaN   \n",
       "1682                    NaN   \n",
       "1683                    NaN   \n",
       "1684                    NaN   \n",
       "1685                    NaN   \n",
       "1686                    NaN   \n",
       "1687                    NaN   \n",
       "1688                    NaN   \n",
       "1689                    NaN   \n",
       "1690                    NaN   \n",
       "1691                    NaN   \n",
       "1692                    NaN   \n",
       "1693                    NaN   \n",
       "1694                    NaN   \n",
       "1695                    NaN   \n",
       "1696                    NaN   \n",
       "1697                    NaN   \n",
       "1698                    NaN   \n",
       "1699                    NaN   \n",
       "1700                    NaN   \n",
       "1701                 KG/M^2   \n",
       "1702                    NaN   \n",
       "1703                    NaN   \n",
       "1704                    NaN   \n",
       "1705                    NaN   \n",
       "1706                    NaN   \n",
       "1707                    NaN   \n",
       "1708                    NaN   \n",
       "\n",
       "                         var_coding_counts_distribution    var_doc_id  \\\n",
       "0     n=4884; nulls=195; HIGH SCHOOL GRADUATE=5:coun...      FHS1var2   \n",
       "1     n=2122; nulls=17; mean=2.82; sd=1.353; median=...     FHS1var16   \n",
       "2                                       n=5079; nulls=0    FHS1var558   \n",
       "3                                       n=3909; nulls=0    FHS2var151   \n",
       "4     n=3712; nulls=0; MARRIED=2:count=2847; WIDOWED...      FHS3var1   \n",
       "5     n=3698; nulls=14; mean=138.7; sd=22.16; median...      FHS3var8   \n",
       "6     n=3699; nulls=13; mean=85.64; sd=11.88; median...      FHS3var9   \n",
       "7     n=3708; nulls=4; mean=140.1; sd=23.46; median=...     FHS3var10   \n",
       "8     n=3705; nulls=7; mean=82.19; sd=11.59; median=...     FHS3var11   \n",
       "9     n=3651; nulls=61; mean=139.1; sd=23.49; median...     FHS3var12   \n",
       "10    n=3650; nulls=62; mean=81.81; sd=11.61; median...     FHS3var13   \n",
       "11    n=3581; nulls=131; mean=241.5; sd=45.62; media...     FHS3var18   \n",
       "12    n=3548; nulls=164; mean=193.3; sd=44.41; media...     FHS3var19   \n",
       "13    n=3547; nulls=165; mean=48.12; sd=14.52; media...     FHS3var20   \n",
       "14    n=3712; nulls=0; NO=2000:count=2006; YES=1:cou...     FHS3var68   \n",
       "15    n=3708; nulls=4; NO=0:count=3553; YES, DEFINIT...    FHS3var114   \n",
       "16    n=3702; nulls=10; NONE=0:count=3653; AORTIC=2:...    FHS3var116   \n",
       "17    n=3710; nulls=2; mean=78.05; sd=12.82; median=...    FHS3var142   \n",
       "18    n=3677; nulls=2; mean=15.79; sd=2.176; median=...    FHS3var143   \n",
       "19    n=3710; nulls=2; NO=0:count=3555; YES, MAYBE=2...    FHS3var146   \n",
       "20    n=3710; nulls=2; NO=0:count=3680; YES=1:count=...    FHS3var152   \n",
       "21    n=3710; nulls=2; NO=0:count=3709; YES=1:count=...    FHS3var153   \n",
       "22    n=3711; nulls=1; NO=0:count=3214; YES, DEFINIT...    FHS3var159   \n",
       "23                                      n=3712; nulls=0    FHS3var176   \n",
       "24    n=2626; nulls=847; mean=235; sd=43.76; median=...     FHS4var17   \n",
       "25    n=2604; nulls=869; mean=186.5; sd=43.17; media...     FHS4var18   \n",
       "26    n=2604; nulls=869; mean=48.49; sd=16.17; media...     FHS4var19   \n",
       "27                                      n=3473; nulls=0    FHS4var196   \n",
       "28    n=1309; nulls=1543; mean=234.3; sd=43.16; medi...     FHS5var22   \n",
       "29    n=1309; nulls=1543; mean=51.93; sd=15.81; medi...     FHS5var23   \n",
       "...                                                 ...           ...   \n",
       "1679                                    n=6412; nulls=0    MESA74var1   \n",
       "1680                                    n=4382; nulls=0    MESA75var1   \n",
       "1681                                    n=5853; nulls=0    MESA76var1   \n",
       "1682                                    n=5756; nulls=0    MESA77var1   \n",
       "1683                                    n=5601; nulls=0    MESA78var1   \n",
       "1684                                    n=5393; nulls=0    MESA79var1   \n",
       "1685                                    n=4382; nulls=0    MESA80var1   \n",
       "1686                                    n=5631; nulls=0    MESA81var1   \n",
       "1687                                    n=6429; nulls=0    MESA82var1   \n",
       "1688                                    n=3385; nulls=0    MESA83var1   \n",
       "1689                                    n=4267; nulls=0    MESA84var1   \n",
       "1690                                    n=1690; nulls=0    MESA85var1   \n",
       "1691                                    n=2800; nulls=0    MESA86var1   \n",
       "1692                                    n=6420; nulls=0    MESA87var1   \n",
       "1693                                    n=5853; nulls=0    MESA88var1   \n",
       "1694                                    n=5756; nulls=0    MESA89var1   \n",
       "1695                                    n=5601; nulls=0    MESA90var1   \n",
       "1696                                    n=5393; nulls=0    MESA91var1   \n",
       "1697                                    n=4382; nulls=0    MESA92var1   \n",
       "1698                                     n=950; nulls=0    MESA93var1   \n",
       "1699  n=950; nulls=0; COMPLETED HIGH SCHOOL/GED=3:co...    MESA93var2   \n",
       "1700  n=950; nulls=0; FEMALE=0:count=494; MALE=1:cou...    MESA93var5   \n",
       "1701  n=949; nulls=1; mean=29.03; sd=5.652; median=2...    MESA93var8   \n",
       "1702  n=5889; nulls=540; NO=0:count=5698; YES=1:coun...     MESA9var7   \n",
       "1703  n=5616; nulls=813; NO=0:count=5439; YES=1:coun...    MESA10var7   \n",
       "1704  n=5494; nulls=935; NO=0:count=5330; YES=1:coun...    MESA11var7   \n",
       "1705  n=1616; nulls=0; BLACK, AFRICAN-AMERICAN=3:cou...    MESA12var5   \n",
       "1706  n=185; nulls=0; mean=3.514; sd=0.5012; median=...   MESA58var83   \n",
       "1707  n=32; nulls=153; BLACK, AFRICAN-AMERICAN=3:cou...  MESA58var148   \n",
       "1708  n=950; nulls=0; HISPANIC=4:count=515; BLACK, A...    MESA93var4   \n",
       "\n",
       "             concept_id         dbGaP_studyID_datasetID_varID  \\\n",
       "0             education        phs000007.v26.pht000009.v2.MF5   \n",
       "1           pregnancies       phs000007.v26.pht000009.v2.MF20   \n",
       "2         ParticipantID    phs000007.v26.pht000009.v2.shareid   \n",
       "3         ParticipantID    phs000007.v26.pht000010.v3.shareid   \n",
       "4         maritalStatus        phs000007.v26.pht000011.v3.FB8   \n",
       "5                   SBP       phs000007.v26.pht000011.v3.FB18   \n",
       "6                   DBP       phs000007.v26.pht000011.v3.FB19   \n",
       "7                   SBP       phs000007.v26.pht000011.v3.FB20   \n",
       "8                   DBP       phs000007.v26.pht000011.v3.FB21   \n",
       "9                   SBP       phs000007.v26.pht000011.v3.FB22   \n",
       "10                  DBP       phs000007.v26.pht000011.v3.FB23   \n",
       "11    cholesterol_mg_dL       phs000007.v26.pht000011.v3.FB28   \n",
       "12             LDLmg_dL       phs000007.v26.pht000011.v3.FB29   \n",
       "13             HDLmg_dL       phs000007.v26.pht000011.v3.FB30   \n",
       "14                smoke       phs000007.v26.pht000011.v3.FB83   \n",
       "15            sysMurmur      phs000007.v26.pht000011.v3.FB146   \n",
       "16         diaMurbinary      phs000007.v26.pht000011.v3.FB148   \n",
       "17                   HR      phs000007.v26.pht000011.v3.FB181   \n",
       "18                   PR      phs000007.v26.pht000011.v3.FB182   \n",
       "19                  LVH      phs000007.v26.pht000011.v3.FB185   \n",
       "20               prevAF      phs000007.v26.pht000011.v3.FB191   \n",
       "21               prevAF      phs000007.v26.pht000011.v3.FB192   \n",
       "22               HTNmed      phs000007.v26.pht000011.v3.FB221   \n",
       "23        ParticipantID    phs000007.v26.pht000011.v3.shareid   \n",
       "24    cholesterol_mg_dL       phs000007.v26.pht000012.v3.FC22   \n",
       "25             LDLmg_dL       phs000007.v26.pht000012.v3.FC23   \n",
       "26             HDLmg_dL       phs000007.v26.pht000012.v3.FC24   \n",
       "27        ParticipantID    phs000007.v26.pht000012.v3.shareid   \n",
       "28    cholesterol_mg_dL       phs000007.v26.pht000013.v3.FD36   \n",
       "29             HDLmg_dL       phs000007.v26.pht000013.v3.FD37   \n",
       "...                 ...                                   ...   \n",
       "1679      ParticipantID      phs000209.v13.pht003479.v1.sidno   \n",
       "1680      ParticipantID      phs000209.v13.pht003604.v2.sidno   \n",
       "1681      ParticipantID      phs000209.v13.pht003605.v1.sidno   \n",
       "1682      ParticipantID      phs000209.v13.pht003606.v1.sidno   \n",
       "1683      ParticipantID      phs000209.v13.pht003607.v1.sidno   \n",
       "1684      ParticipantID      phs000209.v13.pht003608.v1.sidno   \n",
       "1685      ParticipantID      phs000209.v13.pht003609.v1.sidno   \n",
       "1686      ParticipantID      phs000209.v13.pht003610.v1.sidno   \n",
       "1687      ParticipantID      phs000209.v13.pht003659.v1.sidno   \n",
       "1688      ParticipantID      phs000209.v13.pht004316.v1.sidno   \n",
       "1689      ParticipantID      phs000209.v13.pht004317.v1.sidno   \n",
       "1690      ParticipantID      phs000209.v13.pht004318.v1.sidno   \n",
       "1691      ParticipantID      phs000209.v13.pht004319.v1.sidno   \n",
       "1692      ParticipantID      phs000209.v13.pht004320.v1.sidno   \n",
       "1693      ParticipantID      phs000209.v13.pht004321.v1.sidno   \n",
       "1694      ParticipantID      phs000209.v13.pht004322.v1.sidno   \n",
       "1695      ParticipantID      phs000209.v13.pht004323.v1.sidno   \n",
       "1696      ParticipantID      phs000209.v13.pht004324.v1.sidno   \n",
       "1697      ParticipantID      phs000209.v13.pht004325.v1.sidno   \n",
       "1698      ParticipantID      phs000209.v13.pht004326.v1.sidno   \n",
       "1699          education      phs000209.v13.pht004326.v1.educ1   \n",
       "1700             gender    phs000209.v13.pht004326.v1.gender1   \n",
       "1701                BMI      phs000209.v13.pht004326.v1.bmisc   \n",
       "1702     race_ethnicity   phs000209.v13.pht001118.v8.othhisp1   \n",
       "1703     race_ethnicity   phs000209.v13.pht001119.v8.othhisp1   \n",
       "1704     race_ethnicity  phs000209.v13.pht001120.v10.othhisp1   \n",
       "1705     race_ethnicity     phs000209.v13.pht001121.v3.racefc   \n",
       "1706     race_ethnicity       phs000209.v13.pht003087.v1.race   \n",
       "1707     race_ethnicity     phs000209.v13.pht003087.v1.racefc   \n",
       "1708     race_ethnicity     phs000209.v13.pht004326.v1.race1c   \n",
       "\n",
       "                                      var_coding_labels  \n",
       "0     FIFTH, SIXTH OR SEVENTH GRADE; NONE; POST GRAD...  \n",
       "1     MAN, SINGLE WOMAN, OR NO PREGNANCIES FOR NON-S...  \n",
       "2                                                   NaN  \n",
       "3                                                   NaN  \n",
       "4         MARRIED; SEPARATED; SINGLE; WIDOWED; DIVORCED  \n",
       "5                                                   NaN  \n",
       "6                                                   NaN  \n",
       "7                                                   NaN  \n",
       "8                                                   NaN  \n",
       "9                                                   NaN  \n",
       "10                                                  NaN  \n",
       "11                                                  NaN  \n",
       "12                                                  NaN  \n",
       "13                                                  NaN  \n",
       "14                                              NO; YES  \n",
       "15               YES, MAYBE; NO; UNKNOWN; YES, DEFINITE  \n",
       "16           AORTIC; NONE; UNKNOWN; MITRAL; BOTH; OTHER  \n",
       "17                                                  NaN  \n",
       "18    ATRIAL FIBRILLATION; ECG NOT TAKEN; INDETERMINATE  \n",
       "19         YES, MAYBE; NO; ECG NOT TAKEN; YES, DEFINITE  \n",
       "20                               NO; ECG NOT TAKEN; YES  \n",
       "21                               NO; ECG NOT TAKEN; YES  \n",
       "22               YES, MAYBE; NO; UNKNOWN; YES, DEFINITE  \n",
       "23                                                  NaN  \n",
       "24                                                  NaN  \n",
       "25                                                  NaN  \n",
       "26                                                  NaN  \n",
       "27                                                  NaN  \n",
       "28                                                  NaN  \n",
       "29                                                  NaN  \n",
       "...                                                 ...  \n",
       "1679                                                NaN  \n",
       "1680                                                NaN  \n",
       "1681                                                NaN  \n",
       "1682                                                NaN  \n",
       "1683                                                NaN  \n",
       "1684                                                NaN  \n",
       "1685                                                NaN  \n",
       "1686                                                NaN  \n",
       "1687                                                NaN  \n",
       "1688                                                NaN  \n",
       "1689                                                NaN  \n",
       "1690                                                NaN  \n",
       "1691                                                NaN  \n",
       "1692                                                NaN  \n",
       "1693                                                NaN  \n",
       "1694                                                NaN  \n",
       "1695                                                NaN  \n",
       "1696                                                NaN  \n",
       "1697                                                NaN  \n",
       "1698                                                NaN  \n",
       "1699  NO SCHOOLING; GRADES 1-8; GRADES 9-11; COMPLET...  \n",
       "1700                                       FEMALE; MALE  \n",
       "1701                                                NaN  \n",
       "1702                                            NO; YES  \n",
       "1703                                            NO; YES  \n",
       "1704                                            NO; YES  \n",
       "1705  WHITE, CAUCASIAN; CHINESE AMERICAN; BLACK, AFR...  \n",
       "1706                                                NaN  \n",
       "1707  WHITE, CAUCASIAN; CHINESE AMERICAN; BLACK, AFR...  \n",
       "1708  WHITE, CAUCASIAN; CHINESE AMERICAN; BLACK, AFR...  \n",
       "\n",
       "[1709 rows x 14 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(man_file,\n",
    "                       sep=\",\",\n",
    "                       quotechar='\"',\n",
    "                       na_values=\"\",\n",
    "                       low_memory=False)\n",
    "data.shape\n",
    "#data[data[\"var_doc_id\"] == \"escape.admreas.adothr\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dbGaP_study_id</th>\n",
       "      <th>dbGaP_dataset_id</th>\n",
       "      <th>dataset_description</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>variable_description</th>\n",
       "      <th>units</th>\n",
       "      <th>variable_coding_labels</th>\n",
       "      <th>study</th>\n",
       "      <th>dbGaP_dataset_label</th>\n",
       "      <th>variable_coding_counts_distribution</th>\n",
       "      <th>var_doc_id</th>\n",
       "      <th>study_dataset_dbGaP_id</th>\n",
       "      <th>dbGaP_studyID_datasetID_varID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF4</td>\n",
       "      <td>RELATIVE WEIGHT, EXAM 1</td>\n",
       "      <td>PERCENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5036; nulls=43; mean=102.2; sd=16.8; median=...</td>\n",
       "      <td>FHS1var1</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF5</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FIFTH, SIXTH OR SEVENTH GRADE; NONE; POST GRAD...</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4884; nulls=195; HIGH SCHOOL GRADUATE=5:coun...</td>\n",
       "      <td>FHS1var2</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF6</td>\n",
       "      <td>COUNTRY OF BIRTH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BORN IN UNITED STATES; NOT BORN IN UNITED STATES</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5079; nulls=0; BORN IN UNITED STATES=0:count...</td>\n",
       "      <td>FHS1var3</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF8</td>\n",
       "      <td>HISTORY OF ACUTE INFECTIONS, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCARLET FEVER; NEGATIVE; DIPHTHERIA AND FREQUE...</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5029; nulls=50; NEGATIVE=0:count=3087; FREQU...</td>\n",
       "      <td>FHS1var4</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF9</td>\n",
       "      <td>HISTORY OF RHEUMATIC FEVER, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE; DOUBTFUL; UNKNOWN; YES</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5065; nulls=14; NONE=0:count=4738; YES=1:cou...</td>\n",
       "      <td>FHS1var5</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF10</td>\n",
       "      <td>HISTORY OF ALLERGY OR ASTHMA, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BRONCHIAL ASTHMA, ALONE; NEGATIVE; UNKNOWN; AL...</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5019; nulls=60; NEGATIVE=0:count=4467; ALLER...</td>\n",
       "      <td>FHS1var6</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF11</td>\n",
       "      <td>HISTORY OF CHRONIC ARTHRITIS AND RHEUMATISM, E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO; UNKNOWN; YES</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5019; nulls=60; NO=0:count=4360; YES=1:count...</td>\n",
       "      <td>FHS1var7</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF12</td>\n",
       "      <td>HISTORY OF THYROID DISEASE, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HYPOTHYROID ONLY; NEGATIVE; DOUBTFUL; HYPERTHY...</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5054; nulls=25; NEGATIVE=0:count=4726; OTHER...</td>\n",
       "      <td>FHS1var8</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF13</td>\n",
       "      <td>HISTORY OF HYPERTENSION, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERMANENT; NEGATIVE; DOUBTFUL; UNKNOWN; TRANSI...</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5074; nulls=5; NEGATIVE=0:count=4328; TYPE U...</td>\n",
       "      <td>FHS1var9</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF14</td>\n",
       "      <td>HISTORY OF ENLARGED HEART, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO; UNKNOWN; YES</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4943; nulls=136; NO=0:count=4861; YES=1:coun...</td>\n",
       "      <td>FHS1var10</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF15</td>\n",
       "      <td>HISTORY OF NERVOUS HEART, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO; UNKNOWN; YES</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4943; nulls=136; NO=0:count=4899; YES=1:coun...</td>\n",
       "      <td>FHS1var11</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF16</td>\n",
       "      <td>HISTORY OF PERICARDITIS, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO; UNKNOWN; YES</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4943; nulls=136; NO=0:count=4934; YES=1:coun...</td>\n",
       "      <td>FHS1var12</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF17</td>\n",
       "      <td>HISTORY OF SUBACUTE ENDOCARDITIS, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO; UNKNOWN; YES</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4943; nulls=136; NO=0:count=4938; YES=1:coun...</td>\n",
       "      <td>FHS1var13</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF18</td>\n",
       "      <td>HISTORY OF OTHER CARDIOVASCULAR DISEASE, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO; UNKNOWN; YES</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4943; nulls=136; NO=0:count=4756; YES=1:coun...</td>\n",
       "      <td>FHS1var14</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF19</td>\n",
       "      <td>HISTORY OF NON-CARDIOVASCULAR DISEASE, EXAM 1 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHRONIC COLITIS; NEGATIVE; DOUBTFUL; ULCER AND...</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5043; nulls=36; NEGATIVE=0:count=4258; KIDNE...</td>\n",
       "      <td>FHS1var15</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF20</td>\n",
       "      <td>NUMBER OF PREGNANCIES, EXAM 1</td>\n",
       "      <td>NUMBER OF PREGNANCIES</td>\n",
       "      <td>MAN, SINGLE WOMAN, OR NO PREGNANCIES FOR NON-S...</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=2122; nulls=17; mean=2.82; sd=1.353; median=...</td>\n",
       "      <td>FHS1var16</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF21</td>\n",
       "      <td>TOXEMIA WITH ONE OR MORE PREGNANCIES, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO; YES; MAN, SINGLE WOMAN, OR NO PREGNANCIES ...</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5079; nulls=0; MAN, SINGLE WOMAN, OR NO PREG...</td>\n",
       "      <td>FHS1var17</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF22</td>\n",
       "      <td>HISTORY OF DRUGS TAKEN: DIGITALIS OR NITRITES,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NITRITES, ALONE; NEGATIVE; UNKNOWN; DIGITALIS,...</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4935; nulls=144; NEGATIVE=0:count=4776; DIGI...</td>\n",
       "      <td>FHS1var18</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF23</td>\n",
       "      <td>EXAMINATION: INCREASE IN CHEST CIRCUMFERENCE, ...</td>\n",
       "      <td>INCHES</td>\n",
       "      <td>1.0--1.4; LESS THAN 0.5; 4.0 OR OVER; 2.5--2.9...</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4976; nulls=103; 4.0 OR OVER=8:count=1123; 3...</td>\n",
       "      <td>FHS1var19</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF24</td>\n",
       "      <td>EYE EXAMINATION: EXOPHTHALMOS, ARCUS SENILIS, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARCUS SENILIS, ALONE; NONE OF THESE; ARCUS SEN...</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4823; nulls=256; NONE OF THESE=0:count=4242;...</td>\n",
       "      <td>FHS1var20</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF25</td>\n",
       "      <td>EYE EXAMINATION: RETINA, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABNORMAL, GROUP II; NORMAL; ABNORMAL, GROUP UN...</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4823; nulls=256; NORMAL=0:count=3779; ABNORM...</td>\n",
       "      <td>FHS1var21</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF26</td>\n",
       "      <td>CHEST EXAMINATION: DEFORMITY, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO; UNKNOWN; YES</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4738; nulls=341; NO=0:count=4333; YES=1:coun...</td>\n",
       "      <td>FHS1var22</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF27</td>\n",
       "      <td>CHEST EXAMINATION: APEX IMPULSE OUTSIDE MIDCLA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO; UNKNOWN; YES</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4738; nulls=341; NO=0:count=4536; YES=1:coun...</td>\n",
       "      <td>FHS1var23</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF28</td>\n",
       "      <td>CHEST EXAMINATION: RALES, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO; UNKNOWN; YES</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4738; nulls=341; NO=0:count=4499; YES=1:coun...</td>\n",
       "      <td>FHS1var24</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF29</td>\n",
       "      <td>CHEST EXAMINATION: IRREGULAR CARDIAC RHYTHM, E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO; UNKNOWN; YES</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=4738; nulls=341; NO=0:count=4560; YES=1:coun...</td>\n",
       "      <td>FHS1var25</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF30</td>\n",
       "      <td>X-RAY: GENERALIZED HYPERTROPHY, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES, DOUBTFUL; NO; UNKNOWN; YES, DEFINITE</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5048; nulls=31; NO=0:count=4581; YES, DEFINI...</td>\n",
       "      <td>FHS1var26</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF31</td>\n",
       "      <td>X-RAY: LEFT VENTRICULAR HYPERTROPHY, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES, DOUBTFUL; NO; UNKNOWN; YES, DEFINITE</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5048; nulls=31; NO=0:count=4271; YES, DEFINI...</td>\n",
       "      <td>FHS1var27</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF32</td>\n",
       "      <td>X-RAY: OTHER HYPERTROPHY (AH, RVH), EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES, DOUBTFUL; NO; UNKNOWN; YES, DEFINITE</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5048; nulls=31; NO=0:count=4990; YES, DOUBTF...</td>\n",
       "      <td>FHS1var28</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF33</td>\n",
       "      <td>X-RAY: ABNORMAL CONTOUR OTHER THAN HYPERTROPHY...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES, DOUBTFUL; NO; UNKNOWN; YES, DEFINITE</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5048; nulls=31; NO=0:count=4974; YES, DEFINI...</td>\n",
       "      <td>FHS1var29</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>phs000007.v26</td>\n",
       "      <td>pht000009.v2</td>\n",
       "      <td>Clinic Exam, Original Cohort Exams 1 - 7</td>\n",
       "      <td>MF34</td>\n",
       "      <td>X-RAY: ABNORMAL GREAT VESSELS, EXAM 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES, DOUBTFUL; NO; UNKNOWN; YES, DEFINITE</td>\n",
       "      <td>FHS</td>\n",
       "      <td>ex0_7s</td>\n",
       "      <td>n=5048; nulls=31; NO=0:count=3680; YES, DEFINI...</td>\n",
       "      <td>FHS1var30</td>\n",
       "      <td>phs000007.v26.pht000009.v2</td>\n",
       "      <td>phs000007.v26.pht000009.v2.MF34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105581</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004320.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>glyca1m</td>\n",
       "      <td>GlycA Concentration: Missing Value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DNR</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaGlycA</td>\n",
       "      <td>n=11; nulls=6409; DNR=1:count=11</td>\n",
       "      <td>MESA87var3</td>\n",
       "      <td>phs000209.v13.pht004320.v1</td>\n",
       "      <td>phs000209.v13.pht004320.v1.glyca1m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105582</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004320.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>glycacom1</td>\n",
       "      <td>GlycA Lab Comments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaGlycA</td>\n",
       "      <td>n=11; nulls=6409; QC failed='':count=11</td>\n",
       "      <td>MESA87var4</td>\n",
       "      <td>phs000209.v13.pht004320.v1</td>\n",
       "      <td>phs000209.v13.pht004320.v1.glycacom1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105583</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004321.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam1</td>\n",
       "      <td>n=5853; nulls=0</td>\n",
       "      <td>MESA88var1</td>\n",
       "      <td>phs000209.v13.pht004321.v1</td>\n",
       "      <td>phs000209.v13.pht004321.v1.sidno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105584</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004321.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1_PC2_1</td>\n",
       "      <td>Weighted Factor1 scale from the Other SES PCA ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam1</td>\n",
       "      <td>n=5853; nulls=0; mean=-0.2842; sd=1.361; media...</td>\n",
       "      <td>MESA88var2</td>\n",
       "      <td>phs000209.v13.pht004321.v1</td>\n",
       "      <td>phs000209.v13.pht004321.v1.F1_PC2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105585</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004322.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam2</td>\n",
       "      <td>n=5756; nulls=0</td>\n",
       "      <td>MESA89var1</td>\n",
       "      <td>phs000209.v13.pht004322.v1</td>\n",
       "      <td>phs000209.v13.pht004322.v1.sidno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105586</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004322.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1_PC2_2</td>\n",
       "      <td>Weighted Factor1 scale from the Other SES PCA ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam2</td>\n",
       "      <td>n=5755; nulls=1; mean=-0.29; sd=1.352; median=...</td>\n",
       "      <td>MESA89var2</td>\n",
       "      <td>phs000209.v13.pht004322.v1</td>\n",
       "      <td>phs000209.v13.pht004322.v1.F1_PC2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105587</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004323.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam3</td>\n",
       "      <td>n=5601; nulls=0</td>\n",
       "      <td>MESA90var1</td>\n",
       "      <td>phs000209.v13.pht004323.v1</td>\n",
       "      <td>phs000209.v13.pht004323.v1.sidno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105588</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004323.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1_PC2_3</td>\n",
       "      <td>Weighted Factor1 scale from the Other SES PCA ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam3</td>\n",
       "      <td>n=5576; nulls=25; mean=-0.4452; sd=1.326; medi...</td>\n",
       "      <td>MESA90var2</td>\n",
       "      <td>phs000209.v13.pht004323.v1</td>\n",
       "      <td>phs000209.v13.pht004323.v1.F1_PC2_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105589</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004324.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam4</td>\n",
       "      <td>n=5393; nulls=0</td>\n",
       "      <td>MESA91var1</td>\n",
       "      <td>phs000209.v13.pht004324.v1</td>\n",
       "      <td>phs000209.v13.pht004324.v1.sidno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105590</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004324.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1_PC2_4</td>\n",
       "      <td>Weighted Factor1 scale from the Other SES PCA ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam4</td>\n",
       "      <td>n=5333; nulls=60; mean=-0.7355; sd=1.318; medi...</td>\n",
       "      <td>MESA91var2</td>\n",
       "      <td>phs000209.v13.pht004324.v1</td>\n",
       "      <td>phs000209.v13.pht004324.v1.F1_PC2_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105591</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004325.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam5</td>\n",
       "      <td>n=4382; nulls=0</td>\n",
       "      <td>MESA92var1</td>\n",
       "      <td>phs000209.v13.pht004325.v1</td>\n",
       "      <td>phs000209.v13.pht004325.v1.sidno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105592</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004325.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1_PC2_5</td>\n",
       "      <td>Weighted Factor1 scale from the Other SES PCA ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaNeighborSESExam5</td>\n",
       "      <td>n=4277; nulls=105; mean=-0.5151; sd=1.224; med...</td>\n",
       "      <td>MESA92var2</td>\n",
       "      <td>phs000209.v13.pht004325.v1</td>\n",
       "      <td>phs000209.v13.pht004325.v1.F1_PC2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105593</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sidno</td>\n",
       "      <td>SHARE ID NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=950; nulls=0</td>\n",
       "      <td>MESA93var1</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.sidno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105594</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>educ1</td>\n",
       "      <td>EDUCATION: HIGHEST LEVEL COMPLETED AT BASELINE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO SCHOOLING; GRADES 1-8; GRADES 9-11; COMPLET...</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=950; nulls=0; COMPLETED HIGH SCHOOL/GED=3:co...</td>\n",
       "      <td>MESA93var2</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.educ1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105595</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>visit</td>\n",
       "      <td>MESA EXAM INDICATOR AT WHICH STRESS STUDY COMP...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=950; nulls=0; mean=3.344; sd=0.4754; median=...</td>\n",
       "      <td>MESA93var3</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105596</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>race1c</td>\n",
       "      <td>RACE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITE, CAUCASIAN; CHINESE AMERICAN; BLACK, AFR...</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=950; nulls=0; HISPANIC=4:count=515; BLACK, A...</td>\n",
       "      <td>MESA93var4</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.race1c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105597</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gender1</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMALE; MALE</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=950; nulls=0; FEMALE=0:count=494; MALE=1:cou...</td>\n",
       "      <td>MESA93var5</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.gender1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105598</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sitesc</td>\n",
       "      <td>SITE AT STRESS EXAM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WFU; COL; JHU; UMN; NWU; UCLA</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=950; nulls=0; UCLA=8:count=477; COL=4:count=...</td>\n",
       "      <td>MESA93var6</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.sitesc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105599</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>agesc</td>\n",
       "      <td>AGE AT STRESS EXAM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=950; nulls=0; mean=65.36; sd=9.702; median=6...</td>\n",
       "      <td>MESA93var7</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.agesc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105600</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bmisc</td>\n",
       "      <td>BODY MASS INDEX (KG/M^2) AT MESA STRESS EXAM</td>\n",
       "      <td>KG/M^2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=949; nulls=1; mean=29.03; sd=5.652; median=2...</td>\n",
       "      <td>MESA93var8</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.bmisc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105601</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>glucossc</td>\n",
       "      <td>FASTING GLUCOSE- CALIBRATED AT MESA STRESS EXAM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=950; nulls=0; mean=102.8; sd=31.28; median=9...</td>\n",
       "      <td>MESA93var9</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.glucossc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105602</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>il6_ss</td>\n",
       "      <td>IL6 RESULTS (PG/ML)</td>\n",
       "      <td>PG/ML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=913; nulls=37; mean=2.83; sd=1.967; median=2...</td>\n",
       "      <td>MESA93var10</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.il6_ss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105603</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tnfa_ss</td>\n",
       "      <td>TNF ALPHA (PG/ML)</td>\n",
       "      <td>PG/ML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=932; nulls=18; mean=4.443; sd=6.368; median=...</td>\n",
       "      <td>MESA93var11</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.tnfa_ss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105604</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wake_avg</td>\n",
       "      <td>CORTISOL VALUE AT WAKEUP (LOG UNIT) -SUBJECT L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=908; nulls=42; mean=2.387; sd=0.6048; median...</td>\n",
       "      <td>MESA93var12</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.wake_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105605</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>car_avg</td>\n",
       "      <td>CORTISOL AWAKENING RESPONSE  -SUBJECT LEVEL SU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=849; nulls=101; mean=0.3841; sd=0.5023; medi...</td>\n",
       "      <td>MESA93var13</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.car_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105606</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bedtime_avg</td>\n",
       "      <td>CORTISOL VALUE AT BEDTIME (LOG UNIT) -SUBJECT ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=904; nulls=46; mean=0.6514; sd=0.8279; media...</td>\n",
       "      <td>MESA93var14</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.bedtime_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105607</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auc_16hr_avg</td>\n",
       "      <td>AREA UNDER THE CURVE (AUC) 16 HOURS -SUBJECT L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=894; nulls=56; mean=1.516; sd=0.4906; median...</td>\n",
       "      <td>MESA93var15</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.auc_16hr_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105608</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>edslope_pwl_pol</td>\n",
       "      <td>EARLY DECLINE SLOPE OF CORTISOL DAILY CURVE -S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=879; nulls=71; mean=-0.4302; sd=0.432; media...</td>\n",
       "      <td>MESA93var16</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.edslope_pwl_pol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105609</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>odslope_pol</td>\n",
       "      <td>OVERALL DECLINE SLOPE OF CORTISOL DAILY CURVE ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=913; nulls=37; mean=-0.1149; sd=0.06019; med...</td>\n",
       "      <td>MESA93var17</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.odslope_pol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105610</th>\n",
       "      <td>phs000209.v13</td>\n",
       "      <td>pht004326.v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ldslope_smp_pol</td>\n",
       "      <td>LATE DECLINE SLOPE OF CORTISOL DAILY CURVE -SU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESA</td>\n",
       "      <td>MESA_AncilMesaStressWave1</td>\n",
       "      <td>n=900; nulls=50; mean=-0.1197; sd=0.06584; med...</td>\n",
       "      <td>MESA93var18</td>\n",
       "      <td>phs000209.v13.pht004326.v1</td>\n",
       "      <td>phs000209.v13.pht004326.v1.ldslope_smp_pol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105611 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dbGaP_study_id dbGaP_dataset_id  \\\n",
       "0       phs000007.v26     pht000009.v2   \n",
       "1       phs000007.v26     pht000009.v2   \n",
       "2       phs000007.v26     pht000009.v2   \n",
       "3       phs000007.v26     pht000009.v2   \n",
       "4       phs000007.v26     pht000009.v2   \n",
       "5       phs000007.v26     pht000009.v2   \n",
       "6       phs000007.v26     pht000009.v2   \n",
       "7       phs000007.v26     pht000009.v2   \n",
       "8       phs000007.v26     pht000009.v2   \n",
       "9       phs000007.v26     pht000009.v2   \n",
       "10      phs000007.v26     pht000009.v2   \n",
       "11      phs000007.v26     pht000009.v2   \n",
       "12      phs000007.v26     pht000009.v2   \n",
       "13      phs000007.v26     pht000009.v2   \n",
       "14      phs000007.v26     pht000009.v2   \n",
       "15      phs000007.v26     pht000009.v2   \n",
       "16      phs000007.v26     pht000009.v2   \n",
       "17      phs000007.v26     pht000009.v2   \n",
       "18      phs000007.v26     pht000009.v2   \n",
       "19      phs000007.v26     pht000009.v2   \n",
       "20      phs000007.v26     pht000009.v2   \n",
       "21      phs000007.v26     pht000009.v2   \n",
       "22      phs000007.v26     pht000009.v2   \n",
       "23      phs000007.v26     pht000009.v2   \n",
       "24      phs000007.v26     pht000009.v2   \n",
       "25      phs000007.v26     pht000009.v2   \n",
       "26      phs000007.v26     pht000009.v2   \n",
       "27      phs000007.v26     pht000009.v2   \n",
       "28      phs000007.v26     pht000009.v2   \n",
       "29      phs000007.v26     pht000009.v2   \n",
       "...               ...              ...   \n",
       "105581  phs000209.v13     pht004320.v1   \n",
       "105582  phs000209.v13     pht004320.v1   \n",
       "105583  phs000209.v13     pht004321.v1   \n",
       "105584  phs000209.v13     pht004321.v1   \n",
       "105585  phs000209.v13     pht004322.v1   \n",
       "105586  phs000209.v13     pht004322.v1   \n",
       "105587  phs000209.v13     pht004323.v1   \n",
       "105588  phs000209.v13     pht004323.v1   \n",
       "105589  phs000209.v13     pht004324.v1   \n",
       "105590  phs000209.v13     pht004324.v1   \n",
       "105591  phs000209.v13     pht004325.v1   \n",
       "105592  phs000209.v13     pht004325.v1   \n",
       "105593  phs000209.v13     pht004326.v1   \n",
       "105594  phs000209.v13     pht004326.v1   \n",
       "105595  phs000209.v13     pht004326.v1   \n",
       "105596  phs000209.v13     pht004326.v1   \n",
       "105597  phs000209.v13     pht004326.v1   \n",
       "105598  phs000209.v13     pht004326.v1   \n",
       "105599  phs000209.v13     pht004326.v1   \n",
       "105600  phs000209.v13     pht004326.v1   \n",
       "105601  phs000209.v13     pht004326.v1   \n",
       "105602  phs000209.v13     pht004326.v1   \n",
       "105603  phs000209.v13     pht004326.v1   \n",
       "105604  phs000209.v13     pht004326.v1   \n",
       "105605  phs000209.v13     pht004326.v1   \n",
       "105606  phs000209.v13     pht004326.v1   \n",
       "105607  phs000209.v13     pht004326.v1   \n",
       "105608  phs000209.v13     pht004326.v1   \n",
       "105609  phs000209.v13     pht004326.v1   \n",
       "105610  phs000209.v13     pht004326.v1   \n",
       "\n",
       "                             dataset_description      variable_id  \\\n",
       "0       Clinic Exam, Original Cohort Exams 1 - 7              MF4   \n",
       "1       Clinic Exam, Original Cohort Exams 1 - 7              MF5   \n",
       "2       Clinic Exam, Original Cohort Exams 1 - 7              MF6   \n",
       "3       Clinic Exam, Original Cohort Exams 1 - 7              MF8   \n",
       "4       Clinic Exam, Original Cohort Exams 1 - 7              MF9   \n",
       "5       Clinic Exam, Original Cohort Exams 1 - 7             MF10   \n",
       "6       Clinic Exam, Original Cohort Exams 1 - 7             MF11   \n",
       "7       Clinic Exam, Original Cohort Exams 1 - 7             MF12   \n",
       "8       Clinic Exam, Original Cohort Exams 1 - 7             MF13   \n",
       "9       Clinic Exam, Original Cohort Exams 1 - 7             MF14   \n",
       "10      Clinic Exam, Original Cohort Exams 1 - 7             MF15   \n",
       "11      Clinic Exam, Original Cohort Exams 1 - 7             MF16   \n",
       "12      Clinic Exam, Original Cohort Exams 1 - 7             MF17   \n",
       "13      Clinic Exam, Original Cohort Exams 1 - 7             MF18   \n",
       "14      Clinic Exam, Original Cohort Exams 1 - 7             MF19   \n",
       "15      Clinic Exam, Original Cohort Exams 1 - 7             MF20   \n",
       "16      Clinic Exam, Original Cohort Exams 1 - 7             MF21   \n",
       "17      Clinic Exam, Original Cohort Exams 1 - 7             MF22   \n",
       "18      Clinic Exam, Original Cohort Exams 1 - 7             MF23   \n",
       "19      Clinic Exam, Original Cohort Exams 1 - 7             MF24   \n",
       "20      Clinic Exam, Original Cohort Exams 1 - 7             MF25   \n",
       "21      Clinic Exam, Original Cohort Exams 1 - 7             MF26   \n",
       "22      Clinic Exam, Original Cohort Exams 1 - 7             MF27   \n",
       "23      Clinic Exam, Original Cohort Exams 1 - 7             MF28   \n",
       "24      Clinic Exam, Original Cohort Exams 1 - 7             MF29   \n",
       "25      Clinic Exam, Original Cohort Exams 1 - 7             MF30   \n",
       "26      Clinic Exam, Original Cohort Exams 1 - 7             MF31   \n",
       "27      Clinic Exam, Original Cohort Exams 1 - 7             MF32   \n",
       "28      Clinic Exam, Original Cohort Exams 1 - 7             MF33   \n",
       "29      Clinic Exam, Original Cohort Exams 1 - 7             MF34   \n",
       "...                                          ...              ...   \n",
       "105581                                       NaN          glyca1m   \n",
       "105582                                       NaN        glycacom1   \n",
       "105583                                       NaN            sidno   \n",
       "105584                                       NaN         F1_PC2_1   \n",
       "105585                                       NaN            sidno   \n",
       "105586                                       NaN         F1_PC2_2   \n",
       "105587                                       NaN            sidno   \n",
       "105588                                       NaN         F1_PC2_3   \n",
       "105589                                       NaN            sidno   \n",
       "105590                                       NaN         F1_PC2_4   \n",
       "105591                                       NaN            sidno   \n",
       "105592                                       NaN         F1_PC2_5   \n",
       "105593                                       NaN            sidno   \n",
       "105594                                       NaN            educ1   \n",
       "105595                                       NaN            visit   \n",
       "105596                                       NaN           race1c   \n",
       "105597                                       NaN          gender1   \n",
       "105598                                       NaN           sitesc   \n",
       "105599                                       NaN            agesc   \n",
       "105600                                       NaN            bmisc   \n",
       "105601                                       NaN         glucossc   \n",
       "105602                                       NaN           il6_ss   \n",
       "105603                                       NaN          tnfa_ss   \n",
       "105604                                       NaN         wake_avg   \n",
       "105605                                       NaN          car_avg   \n",
       "105606                                       NaN      bedtime_avg   \n",
       "105607                                       NaN     auc_16hr_avg   \n",
       "105608                                       NaN  edslope_pwl_pol   \n",
       "105609                                       NaN      odslope_pol   \n",
       "105610                                       NaN  ldslope_smp_pol   \n",
       "\n",
       "                                     variable_description  \\\n",
       "0                                 RELATIVE WEIGHT, EXAM 1   \n",
       "1                                               EDUCATION   \n",
       "2                                        COUNTRY OF BIRTH   \n",
       "3                     HISTORY OF ACUTE INFECTIONS, EXAM 1   \n",
       "4                      HISTORY OF RHEUMATIC FEVER, EXAM 1   \n",
       "5                    HISTORY OF ALLERGY OR ASTHMA, EXAM 1   \n",
       "6       HISTORY OF CHRONIC ARTHRITIS AND RHEUMATISM, E...   \n",
       "7                      HISTORY OF THYROID DISEASE, EXAM 1   \n",
       "8                         HISTORY OF HYPERTENSION, EXAM 1   \n",
       "9                       HISTORY OF ENLARGED HEART, EXAM 1   \n",
       "10                       HISTORY OF NERVOUS HEART, EXAM 1   \n",
       "11                        HISTORY OF PERICARDITIS, EXAM 1   \n",
       "12               HISTORY OF SUBACUTE ENDOCARDITIS, EXAM 1   \n",
       "13        HISTORY OF OTHER CARDIOVASCULAR DISEASE, EXAM 1   \n",
       "14      HISTORY OF NON-CARDIOVASCULAR DISEASE, EXAM 1 ...   \n",
       "15                          NUMBER OF PREGNANCIES, EXAM 1   \n",
       "16           TOXEMIA WITH ONE OR MORE PREGNANCIES, EXAM 1   \n",
       "17      HISTORY OF DRUGS TAKEN: DIGITALIS OR NITRITES,...   \n",
       "18      EXAMINATION: INCREASE IN CHEST CIRCUMFERENCE, ...   \n",
       "19      EYE EXAMINATION: EXOPHTHALMOS, ARCUS SENILIS, ...   \n",
       "20                        EYE EXAMINATION: RETINA, EXAM 1   \n",
       "21                   CHEST EXAMINATION: DEFORMITY, EXAM 1   \n",
       "22      CHEST EXAMINATION: APEX IMPULSE OUTSIDE MIDCLA...   \n",
       "23                       CHEST EXAMINATION: RALES, EXAM 1   \n",
       "24      CHEST EXAMINATION: IRREGULAR CARDIAC RHYTHM, E...   \n",
       "25                 X-RAY: GENERALIZED HYPERTROPHY, EXAM 1   \n",
       "26            X-RAY: LEFT VENTRICULAR HYPERTROPHY, EXAM 1   \n",
       "27             X-RAY: OTHER HYPERTROPHY (AH, RVH), EXAM 1   \n",
       "28      X-RAY: ABNORMAL CONTOUR OTHER THAN HYPERTROPHY...   \n",
       "29                  X-RAY: ABNORMAL GREAT VESSELS, EXAM 1   \n",
       "...                                                   ...   \n",
       "105581                 GlycA Concentration: Missing Value   \n",
       "105582                                 GlycA Lab Comments   \n",
       "105583                                    SHARE ID Number   \n",
       "105584  Weighted Factor1 scale from the Other SES PCA ...   \n",
       "105585                                    SHARE ID Number   \n",
       "105586  Weighted Factor1 scale from the Other SES PCA ...   \n",
       "105587                                    SHARE ID Number   \n",
       "105588  Weighted Factor1 scale from the Other SES PCA ...   \n",
       "105589                                    SHARE ID Number   \n",
       "105590  Weighted Factor1 scale from the Other SES PCA ...   \n",
       "105591                                    SHARE ID Number   \n",
       "105592  Weighted Factor1 scale from the Other SES PCA ...   \n",
       "105593                                    SHARE ID NUMBER   \n",
       "105594  EDUCATION: HIGHEST LEVEL COMPLETED AT BASELINE...   \n",
       "105595  MESA EXAM INDICATOR AT WHICH STRESS STUDY COMP...   \n",
       "105596                                               RACE   \n",
       "105597                                             GENDER   \n",
       "105598                                SITE AT STRESS EXAM   \n",
       "105599                                 AGE AT STRESS EXAM   \n",
       "105600       BODY MASS INDEX (KG/M^2) AT MESA STRESS EXAM   \n",
       "105601    FASTING GLUCOSE- CALIBRATED AT MESA STRESS EXAM   \n",
       "105602                                IL6 RESULTS (PG/ML)   \n",
       "105603                                  TNF ALPHA (PG/ML)   \n",
       "105604  CORTISOL VALUE AT WAKEUP (LOG UNIT) -SUBJECT L...   \n",
       "105605  CORTISOL AWAKENING RESPONSE  -SUBJECT LEVEL SU...   \n",
       "105606  CORTISOL VALUE AT BEDTIME (LOG UNIT) -SUBJECT ...   \n",
       "105607  AREA UNDER THE CURVE (AUC) 16 HOURS -SUBJECT L...   \n",
       "105608  EARLY DECLINE SLOPE OF CORTISOL DAILY CURVE -S...   \n",
       "105609  OVERALL DECLINE SLOPE OF CORTISOL DAILY CURVE ...   \n",
       "105610  LATE DECLINE SLOPE OF CORTISOL DAILY CURVE -SU...   \n",
       "\n",
       "                        units  \\\n",
       "0                     PERCENT   \n",
       "1                         NaN   \n",
       "2                         NaN   \n",
       "3                         NaN   \n",
       "4                         NaN   \n",
       "5                         NaN   \n",
       "6                         NaN   \n",
       "7                         NaN   \n",
       "8                         NaN   \n",
       "9                         NaN   \n",
       "10                        NaN   \n",
       "11                        NaN   \n",
       "12                        NaN   \n",
       "13                        NaN   \n",
       "14                        NaN   \n",
       "15      NUMBER OF PREGNANCIES   \n",
       "16                        NaN   \n",
       "17                        NaN   \n",
       "18                     INCHES   \n",
       "19                        NaN   \n",
       "20                        NaN   \n",
       "21                        NaN   \n",
       "22                        NaN   \n",
       "23                        NaN   \n",
       "24                        NaN   \n",
       "25                        NaN   \n",
       "26                        NaN   \n",
       "27                        NaN   \n",
       "28                        NaN   \n",
       "29                        NaN   \n",
       "...                       ...   \n",
       "105581                    NaN   \n",
       "105582                    NaN   \n",
       "105583                    NaN   \n",
       "105584                    NaN   \n",
       "105585                    NaN   \n",
       "105586                    NaN   \n",
       "105587                    NaN   \n",
       "105588                    NaN   \n",
       "105589                    NaN   \n",
       "105590                    NaN   \n",
       "105591                    NaN   \n",
       "105592                    NaN   \n",
       "105593                    NaN   \n",
       "105594                    NaN   \n",
       "105595                    NaN   \n",
       "105596                    NaN   \n",
       "105597                    NaN   \n",
       "105598                    NaN   \n",
       "105599                    NaN   \n",
       "105600                 KG/M^2   \n",
       "105601                    NaN   \n",
       "105602                  PG/ML   \n",
       "105603                  PG/ML   \n",
       "105604                    NaN   \n",
       "105605                    NaN   \n",
       "105606                    NaN   \n",
       "105607                    NaN   \n",
       "105608                    NaN   \n",
       "105609                    NaN   \n",
       "105610                    NaN   \n",
       "\n",
       "                                   variable_coding_labels study  \\\n",
       "0                                                     NaN   FHS   \n",
       "1       FIFTH, SIXTH OR SEVENTH GRADE; NONE; POST GRAD...   FHS   \n",
       "2        BORN IN UNITED STATES; NOT BORN IN UNITED STATES   FHS   \n",
       "3       SCARLET FEVER; NEGATIVE; DIPHTHERIA AND FREQUE...   FHS   \n",
       "4                            NONE; DOUBTFUL; UNKNOWN; YES   FHS   \n",
       "5       BRONCHIAL ASTHMA, ALONE; NEGATIVE; UNKNOWN; AL...   FHS   \n",
       "6                                        NO; UNKNOWN; YES   FHS   \n",
       "7       HYPOTHYROID ONLY; NEGATIVE; DOUBTFUL; HYPERTHY...   FHS   \n",
       "8       PERMANENT; NEGATIVE; DOUBTFUL; UNKNOWN; TRANSI...   FHS   \n",
       "9                                        NO; UNKNOWN; YES   FHS   \n",
       "10                                       NO; UNKNOWN; YES   FHS   \n",
       "11                                       NO; UNKNOWN; YES   FHS   \n",
       "12                                       NO; UNKNOWN; YES   FHS   \n",
       "13                                       NO; UNKNOWN; YES   FHS   \n",
       "14      CHRONIC COLITIS; NEGATIVE; DOUBTFUL; ULCER AND...   FHS   \n",
       "15      MAN, SINGLE WOMAN, OR NO PREGNANCIES FOR NON-S...   FHS   \n",
       "16      NO; YES; MAN, SINGLE WOMAN, OR NO PREGNANCIES ...   FHS   \n",
       "17      NITRITES, ALONE; NEGATIVE; UNKNOWN; DIGITALIS,...   FHS   \n",
       "18      1.0--1.4; LESS THAN 0.5; 4.0 OR OVER; 2.5--2.9...   FHS   \n",
       "19      ARCUS SENILIS, ALONE; NONE OF THESE; ARCUS SEN...   FHS   \n",
       "20      ABNORMAL, GROUP II; NORMAL; ABNORMAL, GROUP UN...   FHS   \n",
       "21                                       NO; UNKNOWN; YES   FHS   \n",
       "22                                       NO; UNKNOWN; YES   FHS   \n",
       "23                                       NO; UNKNOWN; YES   FHS   \n",
       "24                                       NO; UNKNOWN; YES   FHS   \n",
       "25              YES, DOUBTFUL; NO; UNKNOWN; YES, DEFINITE   FHS   \n",
       "26              YES, DOUBTFUL; NO; UNKNOWN; YES, DEFINITE   FHS   \n",
       "27              YES, DOUBTFUL; NO; UNKNOWN; YES, DEFINITE   FHS   \n",
       "28              YES, DOUBTFUL; NO; UNKNOWN; YES, DEFINITE   FHS   \n",
       "29              YES, DOUBTFUL; NO; UNKNOWN; YES, DEFINITE   FHS   \n",
       "...                                                   ...   ...   \n",
       "105581                                                DNR  MESA   \n",
       "105582                                                NaN  MESA   \n",
       "105583                                                NaN  MESA   \n",
       "105584                                                NaN  MESA   \n",
       "105585                                                NaN  MESA   \n",
       "105586                                                NaN  MESA   \n",
       "105587                                                NaN  MESA   \n",
       "105588                                                NaN  MESA   \n",
       "105589                                                NaN  MESA   \n",
       "105590                                                NaN  MESA   \n",
       "105591                                                NaN  MESA   \n",
       "105592                                                NaN  MESA   \n",
       "105593                                                NaN  MESA   \n",
       "105594  NO SCHOOLING; GRADES 1-8; GRADES 9-11; COMPLET...  MESA   \n",
       "105595                                                NaN  MESA   \n",
       "105596  WHITE, CAUCASIAN; CHINESE AMERICAN; BLACK, AFR...  MESA   \n",
       "105597                                       FEMALE; MALE  MESA   \n",
       "105598                      WFU; COL; JHU; UMN; NWU; UCLA  MESA   \n",
       "105599                                                NaN  MESA   \n",
       "105600                                                NaN  MESA   \n",
       "105601                                                NaN  MESA   \n",
       "105602                                                NaN  MESA   \n",
       "105603                                                NaN  MESA   \n",
       "105604                                                NaN  MESA   \n",
       "105605                                                NaN  MESA   \n",
       "105606                                                NaN  MESA   \n",
       "105607                                                NaN  MESA   \n",
       "105608                                                NaN  MESA   \n",
       "105609                                                NaN  MESA   \n",
       "105610                                                NaN  MESA   \n",
       "\n",
       "                   dbGaP_dataset_label  \\\n",
       "0                               ex0_7s   \n",
       "1                               ex0_7s   \n",
       "2                               ex0_7s   \n",
       "3                               ex0_7s   \n",
       "4                               ex0_7s   \n",
       "5                               ex0_7s   \n",
       "6                               ex0_7s   \n",
       "7                               ex0_7s   \n",
       "8                               ex0_7s   \n",
       "9                               ex0_7s   \n",
       "10                              ex0_7s   \n",
       "11                              ex0_7s   \n",
       "12                              ex0_7s   \n",
       "13                              ex0_7s   \n",
       "14                              ex0_7s   \n",
       "15                              ex0_7s   \n",
       "16                              ex0_7s   \n",
       "17                              ex0_7s   \n",
       "18                              ex0_7s   \n",
       "19                              ex0_7s   \n",
       "20                              ex0_7s   \n",
       "21                              ex0_7s   \n",
       "22                              ex0_7s   \n",
       "23                              ex0_7s   \n",
       "24                              ex0_7s   \n",
       "25                              ex0_7s   \n",
       "26                              ex0_7s   \n",
       "27                              ex0_7s   \n",
       "28                              ex0_7s   \n",
       "29                              ex0_7s   \n",
       "...                                ...   \n",
       "105581             MESA_AncilMesaGlycA   \n",
       "105582             MESA_AncilMesaGlycA   \n",
       "105583  MESA_AncilMesaNeighborSESExam1   \n",
       "105584  MESA_AncilMesaNeighborSESExam1   \n",
       "105585  MESA_AncilMesaNeighborSESExam2   \n",
       "105586  MESA_AncilMesaNeighborSESExam2   \n",
       "105587  MESA_AncilMesaNeighborSESExam3   \n",
       "105588  MESA_AncilMesaNeighborSESExam3   \n",
       "105589  MESA_AncilMesaNeighborSESExam4   \n",
       "105590  MESA_AncilMesaNeighborSESExam4   \n",
       "105591  MESA_AncilMesaNeighborSESExam5   \n",
       "105592  MESA_AncilMesaNeighborSESExam5   \n",
       "105593       MESA_AncilMesaStressWave1   \n",
       "105594       MESA_AncilMesaStressWave1   \n",
       "105595       MESA_AncilMesaStressWave1   \n",
       "105596       MESA_AncilMesaStressWave1   \n",
       "105597       MESA_AncilMesaStressWave1   \n",
       "105598       MESA_AncilMesaStressWave1   \n",
       "105599       MESA_AncilMesaStressWave1   \n",
       "105600       MESA_AncilMesaStressWave1   \n",
       "105601       MESA_AncilMesaStressWave1   \n",
       "105602       MESA_AncilMesaStressWave1   \n",
       "105603       MESA_AncilMesaStressWave1   \n",
       "105604       MESA_AncilMesaStressWave1   \n",
       "105605       MESA_AncilMesaStressWave1   \n",
       "105606       MESA_AncilMesaStressWave1   \n",
       "105607       MESA_AncilMesaStressWave1   \n",
       "105608       MESA_AncilMesaStressWave1   \n",
       "105609       MESA_AncilMesaStressWave1   \n",
       "105610       MESA_AncilMesaStressWave1   \n",
       "\n",
       "                      variable_coding_counts_distribution   var_doc_id  \\\n",
       "0       n=5036; nulls=43; mean=102.2; sd=16.8; median=...     FHS1var1   \n",
       "1       n=4884; nulls=195; HIGH SCHOOL GRADUATE=5:coun...     FHS1var2   \n",
       "2       n=5079; nulls=0; BORN IN UNITED STATES=0:count...     FHS1var3   \n",
       "3       n=5029; nulls=50; NEGATIVE=0:count=3087; FREQU...     FHS1var4   \n",
       "4       n=5065; nulls=14; NONE=0:count=4738; YES=1:cou...     FHS1var5   \n",
       "5       n=5019; nulls=60; NEGATIVE=0:count=4467; ALLER...     FHS1var6   \n",
       "6       n=5019; nulls=60; NO=0:count=4360; YES=1:count...     FHS1var7   \n",
       "7       n=5054; nulls=25; NEGATIVE=0:count=4726; OTHER...     FHS1var8   \n",
       "8       n=5074; nulls=5; NEGATIVE=0:count=4328; TYPE U...     FHS1var9   \n",
       "9       n=4943; nulls=136; NO=0:count=4861; YES=1:coun...    FHS1var10   \n",
       "10      n=4943; nulls=136; NO=0:count=4899; YES=1:coun...    FHS1var11   \n",
       "11      n=4943; nulls=136; NO=0:count=4934; YES=1:coun...    FHS1var12   \n",
       "12      n=4943; nulls=136; NO=0:count=4938; YES=1:coun...    FHS1var13   \n",
       "13      n=4943; nulls=136; NO=0:count=4756; YES=1:coun...    FHS1var14   \n",
       "14      n=5043; nulls=36; NEGATIVE=0:count=4258; KIDNE...    FHS1var15   \n",
       "15      n=2122; nulls=17; mean=2.82; sd=1.353; median=...    FHS1var16   \n",
       "16      n=5079; nulls=0; MAN, SINGLE WOMAN, OR NO PREG...    FHS1var17   \n",
       "17      n=4935; nulls=144; NEGATIVE=0:count=4776; DIGI...    FHS1var18   \n",
       "18      n=4976; nulls=103; 4.0 OR OVER=8:count=1123; 3...    FHS1var19   \n",
       "19      n=4823; nulls=256; NONE OF THESE=0:count=4242;...    FHS1var20   \n",
       "20      n=4823; nulls=256; NORMAL=0:count=3779; ABNORM...    FHS1var21   \n",
       "21      n=4738; nulls=341; NO=0:count=4333; YES=1:coun...    FHS1var22   \n",
       "22      n=4738; nulls=341; NO=0:count=4536; YES=1:coun...    FHS1var23   \n",
       "23      n=4738; nulls=341; NO=0:count=4499; YES=1:coun...    FHS1var24   \n",
       "24      n=4738; nulls=341; NO=0:count=4560; YES=1:coun...    FHS1var25   \n",
       "25      n=5048; nulls=31; NO=0:count=4581; YES, DEFINI...    FHS1var26   \n",
       "26      n=5048; nulls=31; NO=0:count=4271; YES, DEFINI...    FHS1var27   \n",
       "27      n=5048; nulls=31; NO=0:count=4990; YES, DOUBTF...    FHS1var28   \n",
       "28      n=5048; nulls=31; NO=0:count=4974; YES, DEFINI...    FHS1var29   \n",
       "29      n=5048; nulls=31; NO=0:count=3680; YES, DEFINI...    FHS1var30   \n",
       "...                                                   ...          ...   \n",
       "105581                   n=11; nulls=6409; DNR=1:count=11   MESA87var3   \n",
       "105582            n=11; nulls=6409; QC failed='':count=11   MESA87var4   \n",
       "105583                                    n=5853; nulls=0   MESA88var1   \n",
       "105584  n=5853; nulls=0; mean=-0.2842; sd=1.361; media...   MESA88var2   \n",
       "105585                                    n=5756; nulls=0   MESA89var1   \n",
       "105586  n=5755; nulls=1; mean=-0.29; sd=1.352; median=...   MESA89var2   \n",
       "105587                                    n=5601; nulls=0   MESA90var1   \n",
       "105588  n=5576; nulls=25; mean=-0.4452; sd=1.326; medi...   MESA90var2   \n",
       "105589                                    n=5393; nulls=0   MESA91var1   \n",
       "105590  n=5333; nulls=60; mean=-0.7355; sd=1.318; medi...   MESA91var2   \n",
       "105591                                    n=4382; nulls=0   MESA92var1   \n",
       "105592  n=4277; nulls=105; mean=-0.5151; sd=1.224; med...   MESA92var2   \n",
       "105593                                     n=950; nulls=0   MESA93var1   \n",
       "105594  n=950; nulls=0; COMPLETED HIGH SCHOOL/GED=3:co...   MESA93var2   \n",
       "105595  n=950; nulls=0; mean=3.344; sd=0.4754; median=...   MESA93var3   \n",
       "105596  n=950; nulls=0; HISPANIC=4:count=515; BLACK, A...   MESA93var4   \n",
       "105597  n=950; nulls=0; FEMALE=0:count=494; MALE=1:cou...   MESA93var5   \n",
       "105598  n=950; nulls=0; UCLA=8:count=477; COL=4:count=...   MESA93var6   \n",
       "105599  n=950; nulls=0; mean=65.36; sd=9.702; median=6...   MESA93var7   \n",
       "105600  n=949; nulls=1; mean=29.03; sd=5.652; median=2...   MESA93var8   \n",
       "105601  n=950; nulls=0; mean=102.8; sd=31.28; median=9...   MESA93var9   \n",
       "105602  n=913; nulls=37; mean=2.83; sd=1.967; median=2...  MESA93var10   \n",
       "105603  n=932; nulls=18; mean=4.443; sd=6.368; median=...  MESA93var11   \n",
       "105604  n=908; nulls=42; mean=2.387; sd=0.6048; median...  MESA93var12   \n",
       "105605  n=849; nulls=101; mean=0.3841; sd=0.5023; medi...  MESA93var13   \n",
       "105606  n=904; nulls=46; mean=0.6514; sd=0.8279; media...  MESA93var14   \n",
       "105607  n=894; nulls=56; mean=1.516; sd=0.4906; median...  MESA93var15   \n",
       "105608  n=879; nulls=71; mean=-0.4302; sd=0.432; media...  MESA93var16   \n",
       "105609  n=913; nulls=37; mean=-0.1149; sd=0.06019; med...  MESA93var17   \n",
       "105610  n=900; nulls=50; mean=-0.1197; sd=0.06584; med...  MESA93var18   \n",
       "\n",
       "            study_dataset_dbGaP_id               dbGaP_studyID_datasetID_varID  \n",
       "0       phs000007.v26.pht000009.v2              phs000007.v26.pht000009.v2.MF4  \n",
       "1       phs000007.v26.pht000009.v2              phs000007.v26.pht000009.v2.MF5  \n",
       "2       phs000007.v26.pht000009.v2              phs000007.v26.pht000009.v2.MF6  \n",
       "3       phs000007.v26.pht000009.v2              phs000007.v26.pht000009.v2.MF8  \n",
       "4       phs000007.v26.pht000009.v2              phs000007.v26.pht000009.v2.MF9  \n",
       "5       phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF10  \n",
       "6       phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF11  \n",
       "7       phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF12  \n",
       "8       phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF13  \n",
       "9       phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF14  \n",
       "10      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF15  \n",
       "11      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF16  \n",
       "12      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF17  \n",
       "13      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF18  \n",
       "14      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF19  \n",
       "15      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF20  \n",
       "16      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF21  \n",
       "17      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF22  \n",
       "18      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF23  \n",
       "19      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF24  \n",
       "20      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF25  \n",
       "21      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF26  \n",
       "22      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF27  \n",
       "23      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF28  \n",
       "24      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF29  \n",
       "25      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF30  \n",
       "26      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF31  \n",
       "27      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF32  \n",
       "28      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF33  \n",
       "29      phs000007.v26.pht000009.v2             phs000007.v26.pht000009.v2.MF34  \n",
       "...                            ...                                         ...  \n",
       "105581  phs000209.v13.pht004320.v1          phs000209.v13.pht004320.v1.glyca1m  \n",
       "105582  phs000209.v13.pht004320.v1        phs000209.v13.pht004320.v1.glycacom1  \n",
       "105583  phs000209.v13.pht004321.v1            phs000209.v13.pht004321.v1.sidno  \n",
       "105584  phs000209.v13.pht004321.v1         phs000209.v13.pht004321.v1.F1_PC2_1  \n",
       "105585  phs000209.v13.pht004322.v1            phs000209.v13.pht004322.v1.sidno  \n",
       "105586  phs000209.v13.pht004322.v1         phs000209.v13.pht004322.v1.F1_PC2_2  \n",
       "105587  phs000209.v13.pht004323.v1            phs000209.v13.pht004323.v1.sidno  \n",
       "105588  phs000209.v13.pht004323.v1         phs000209.v13.pht004323.v1.F1_PC2_3  \n",
       "105589  phs000209.v13.pht004324.v1            phs000209.v13.pht004324.v1.sidno  \n",
       "105590  phs000209.v13.pht004324.v1         phs000209.v13.pht004324.v1.F1_PC2_4  \n",
       "105591  phs000209.v13.pht004325.v1            phs000209.v13.pht004325.v1.sidno  \n",
       "105592  phs000209.v13.pht004325.v1         phs000209.v13.pht004325.v1.F1_PC2_5  \n",
       "105593  phs000209.v13.pht004326.v1            phs000209.v13.pht004326.v1.sidno  \n",
       "105594  phs000209.v13.pht004326.v1            phs000209.v13.pht004326.v1.educ1  \n",
       "105595  phs000209.v13.pht004326.v1            phs000209.v13.pht004326.v1.visit  \n",
       "105596  phs000209.v13.pht004326.v1           phs000209.v13.pht004326.v1.race1c  \n",
       "105597  phs000209.v13.pht004326.v1          phs000209.v13.pht004326.v1.gender1  \n",
       "105598  phs000209.v13.pht004326.v1           phs000209.v13.pht004326.v1.sitesc  \n",
       "105599  phs000209.v13.pht004326.v1            phs000209.v13.pht004326.v1.agesc  \n",
       "105600  phs000209.v13.pht004326.v1            phs000209.v13.pht004326.v1.bmisc  \n",
       "105601  phs000209.v13.pht004326.v1         phs000209.v13.pht004326.v1.glucossc  \n",
       "105602  phs000209.v13.pht004326.v1           phs000209.v13.pht004326.v1.il6_ss  \n",
       "105603  phs000209.v13.pht004326.v1          phs000209.v13.pht004326.v1.tnfa_ss  \n",
       "105604  phs000209.v13.pht004326.v1         phs000209.v13.pht004326.v1.wake_avg  \n",
       "105605  phs000209.v13.pht004326.v1          phs000209.v13.pht004326.v1.car_avg  \n",
       "105606  phs000209.v13.pht004326.v1      phs000209.v13.pht004326.v1.bedtime_avg  \n",
       "105607  phs000209.v13.pht004326.v1     phs000209.v13.pht004326.v1.auc_16hr_avg  \n",
       "105608  phs000209.v13.pht004326.v1  phs000209.v13.pht004326.v1.edslope_pwl_pol  \n",
       "105609  phs000209.v13.pht004326.v1      phs000209.v13.pht004326.v1.odslope_pol  \n",
       "105610  phs000209.v13.pht004326.v1  phs000209.v13.pht004326.v1.ldslope_smp_pol  \n",
       "\n",
       "[105611 rows x 13 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105611, 13)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv(data_file,\n",
    "                       sep=\",\",\n",
    "                       quotechar='\"',\n",
    "                       na_values=\"\",\n",
    "                       low_memory=False)\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27946"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_ids = list(data2[data2[\"dbGaP_study_id\"]==\"SNOMED\"][ref_id_col])\n",
    "len(pair_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bioWordVec embeddings with regular tfidf\n",
    "vec_file_dir = \"/data/WordVectors2/\"\n",
    "binary_file_name = vec_file_dir + \"BioWordVec_PubMed_MIMICIII_d200.vec.bin\"\n",
    "biowordvec_embeddings = KeyedVectors.load_word2vec_format(binary_file_name, binary=True, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_groups(data, group_col, corpora, pair_id, ref_id):\n",
    "    corpus_doc_ids = [doc_id for doc_id, _ in corpora]\n",
    "    ref_idx = corpus_doc_ids.index(ref_id)\n",
    "    pair_idx = corpus_doc_ids.index(pair_id)\n",
    "    return data[pair_idx][group_col] == data[ref_idx][group_col]\n",
    "\n",
    "\n",
    "def pairable_by_group(data, group_col, corpus_doc_ids, score, pair_id, _, ref_id):\n",
    "    return vocab_similarity.default_pairable(score, pair_id, None, ref_id) and not matching_groups(data, group_col, corpus_doc_ids, pair_id, ref_id)\n",
    "\n",
    "\n",
    "def calc_score_results(data_file, doc_cols, doc_col_key, ref_id_col, filter_file, \n",
    "                       word_vectors=None, \n",
    "                       corpora_col=None, \n",
    "                       pair_ids_col=None):\n",
    "    print data_file\n",
    "    print \"doc_col_key: \" + doc_col_key\n",
    "    data = pd.read_csv(data_file, sep=\",\",quotechar='\"', na_values=\"\",low_memory=False)\n",
    "    \n",
    "    if corpora_col:\n",
    "        corpora_data = corpus.partition(data, corpora_col)\n",
    "    else:\n",
    "        corpora_data = [data]\n",
    "    \n",
    "    if filter_file != data_file:\n",
    "        filter_data = pd.read_csv(filter_file,\n",
    "                                  sep=\",\",\n",
    "                                  quotechar='\"',\n",
    "                                  na_values=\"\",\n",
    "                                  low_memory=False)\n",
    "    else:\n",
    "        filter_data = data\n",
    "        \n",
    "    print(\" Building Corpora...\")\n",
    "    corpora = corpus.build_corpora(doc_cols, corpora_data, ref_id_col, num_cpus=num_cpus)\n",
    "    print(\"Corpus: \", len(corpora), \" \", len([doc for c in corpora for doc in c]))\n",
    "    \n",
    "    print(\"  Calculating BOW matrix...\")\n",
    "    vocab, bow = corpus.calc_tfidf(corpora)\n",
    "    print(\"tfidf matrix size: \" + str(bow.shape))\n",
    "    \n",
    "    # calculate embeddings\n",
    "    if word_vectors:\n",
    "        print(\"  Calculating doc embeddings matrix...\")\n",
    "        doc_ids, doc_vectors = corpus.calc_doc_embeddings(bow.toarray(), vocab, word_vectors, corpora)\n",
    "        print(\"doc_ids: \", len(doc_ids), \" vecs: \", len(doc_vectors))\n",
    "    else:\n",
    "        doc_ids = [doc for c in corpora for doc, _ in c]\n",
    "        doc_vectors = bow.toarray()\n",
    "    \n",
    "    print(\"doc vectors size \" + str(doc_vectors.shape))\n",
    "    \n",
    "    tfidf_label = \"multtfcdf\" if corpora_col else \"tfidf\"\n",
    "    embed_label = \"embed\" if word_vectors else None\n",
    "    \n",
    "    out_suffix = None\n",
    "    \n",
    "    out_file_name = str.join('_', [i for i in [out_prefix, \n",
    "                                               input_data_type, \n",
    "                                               tfidf_label, \n",
    "                                               embed_label, \n",
    "                                               doc_col_key,\n",
    "                                               out_suffix] \n",
    "                                   if i])\n",
    "    out_file = output_dir + out_file_name + \".csv\"\n",
    "    \n",
    "    ref_ids = filter_data[ref_id_col]\n",
    "    \n",
    "    print(\"  Calculating Similarity Scores...\")\n",
    "    scores = vocab_similarity.VariableSimilarityCalculator(ref_ids, pairable=default_pairable)\n",
    "    scores.init_cache(file_name=out_file)\n",
    "\n",
    "    result = scores.score_variables(doc_ids, bow, num_cpus=num_cpus, file_name=out_file, pair_ids=pair_ids)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calc_scores_doc_cols(data_file, doc_cols_inputs, ref_id_col, filter_file, corpora_col=None, word_vectors=None, pair_ids_col=None):\n",
    "    [calc_score_results(data_file, \n",
    "                        doc_cols_inputs[key], \n",
    "                        key, \n",
    "                        ref_id_col, \n",
    "                        filter_file, \n",
    "                        corpora_col=corpora_col, \n",
    "                        word_vectors=word_vectors, \n",
    "                        pair_ids_col=pair_ids_col) \n",
    "     for key in doc_cols_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'automatic_variable_mapping.vocab_similarity' from 'automatic_variable_mapping/vocab_similarity.pyc'>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(corpus)\n",
    "reload(vocab_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Laura/tiff_laura_shared/var_doc_HF_clin_trials_biolincc_NLP.csv\n",
      "doc_col_key: desc\n",
      " Building Corpora...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7028/7028 [00:16<00:00, 415.50it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Corpus: ', 1, ' ', 7028)\n",
      "  Calculating BOW matrix...\n",
      "('vocab size: ', 2334)\n",
      "tfidf matrix size: (7028, 2334)\n",
      "  Calculating doc embeddings matrix...\n",
      "29 documents deleted because document embeddings was all zeros\n",
      "('doc_ids: ', 6999, ' vecs: ', 6999)\n",
      "doc vectors size (6999, 200)\n",
      "  Calculating Similarity Scores...\n",
      "Finding valid pair ids\n",
      "Pair ids: 6999\n",
      "Finding valid ref ids\n",
      "Ref ids: 453\n",
      "Multiplying matrices\n",
      "LHS: (6999, 2334)\n",
      "RHS: (453, 2334)\n",
      "Sim Matrix: (453, 6999)\n",
      "Chunk size: 33\n",
      "Finding matches for 0 carress.a_base.age\n",
      "Finding matches for 100 escape.mhist.htn\n",
      "Finding matches for 200 exact.a_visitsumm.cl_ntpro\n",
      "Finding matches for 400 topcat.t004.ef\n",
      "Finding matches for 300 relax.medhist1.alcoholc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 453/453 [00:00<00:00, 329979.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Laura/tiff_laura_shared/var_doc_HF_clin_trials_biolincc_NLP.csv\n",
      "doc_col_key: desc\n",
      " Building Corpora...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7028/7028 [00:06<00:00, 1126.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Corpus: ', 1, ' ', 7028)\n",
      "  Calculating BOW matrix...\n",
      "('vocab size: ', 2334)\n",
      "tfidf matrix size: (7028, 2334)\n",
      "doc vectors size (7028, 2334)\n",
      "  Calculating Similarity Scores...\n",
      "Finding valid pair ids\n",
      "Pair ids: 7028\n",
      "Finding valid ref ids\n",
      "Ref ids: 453\n",
      "Multiplying matrices\n",
      "LHS: (7028, 2334)\n",
      "RHS: (453, 2334)\n",
      "Sim Matrix: (453, 7028)\n",
      "Chunk size: 33\n",
      "Finding matches for 0 carress.a_base.age\n",
      "Finding matches for 100 escape.mhist.htn\n",
      "Finding matches for 200 exact.a_visitsumm.cl_ntpro\n",
      "Finding matches for 300 relax.medhist1.alcoholc\n",
      "Finding matches for 400 topcat.t004.ef"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 453/453 [00:00<00:00, 224032.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/Laura/tiff_laura_shared/var_doc_HF_clin_trials_biolincc_NLP.csv\n",
      "doc_col_key: desc\n",
      " Building Corpora...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520/520 [00:10<00:00, 49.94it/s]\n",
      "100%|██████████| 2993/2993 [00:05<00:00, 550.88it/s] \n",
      "100%|██████████| 671/671 [00:05<00:00, 114.19it/s]\n",
      "100%|██████████| 1165/1165 [00:04<00:00, 251.21it/s]\n",
      "100%|██████████| 553/553 [00:04<00:00, 118.07it/s]\n",
      "100%|██████████| 1126/1126 [00:03<00:00, 326.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Corpus: ', 6, ' ', 7028)\n",
      "  Calculating BOW matrix...\n",
      "('vocab size: ', 2334)\n",
      "tfidf matrix size: (7028, 2334)\n",
      "doc vectors size (7028, 2334)\n",
      "  Calculating Similarity Scores...\n",
      "Finding valid pair ids\n",
      "Pair ids: 7028\n",
      "Finding valid ref ids\n",
      "Ref ids: 453\n",
      "Multiplying matrices\n",
      "LHS: (7028, 2334)\n",
      "RHS: (453, 2334)\n",
      "Sim Matrix: (453, 7028)\n",
      "Chunk size: 33\n",
      "Finding matches for 0 carress.a_base.age\n",
      "Finding matches for 100 escape.mhist.htn\n",
      "Finding matches for 200 exact.a_visitsumm.cl_ntpro\n",
      "Finding matches for 300 relax.medhist1.alcoholc\n",
      "Finding matches for 400 topcat.t004.ef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 453/453 [00:00<00:00, 289108.29it/s]\n"
     ]
    }
   ],
   "source": [
    "scores_embed = calc_scores_doc_cols(data_file, doc_cols_inputs, ref_id_col, man_file, word_vectors=biowordvec_embeddings, pair_ids_col=None)\n",
    "scores_tfidf = calc_scores_doc_cols(data_file, doc_cols_inputs, ref_id_col, man_file, word_vectors=None, pair_ids_col=None)\n",
    "scores_tfmcdf = calc_scores_doc_cols(data_file, mult_doc_cols_inputs, ref_id_col, man_file, word_vectors=None, corpora_col='study', pair_ids_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top N words from concept vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Laura/tiff_laura_shared/\"\n",
    "top_words_prefix = \"top_n_words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ref_id_col = ref_id_col\n",
    "out_prefix = \"concept_vec_sim_scores_gold_standard\"\n",
    "man_file_name = \"manual_concept_var_mappings_obs_heart_studies_dbGaP_NLP\"\n",
    "man_file = input_dir + man_file_name + \".csv\"\n",
    "man_file_name = \"concept_groups_gold_standard\"\n",
    "concept_id_col = \"concept\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_prefix = \"concept_vec_sim_scores\"\n",
    "man_file_name = \"concept_groups_reference_MESA_vars\"\n",
    "man_file = \"/Laura/tiff_laura_shared/\" + \"\" + man_file_name + \".csv\"\n",
    "concept_id_col = \"pred_concept_id\"\n",
    "filter_ref_id_col = ref_id_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_prefix = \"concept_vec_sim_scores\"\n",
    "man_file_name = \"concept_groups_communities\"\n",
    "man_file = \"/Laura/tiff_laura_shared/\" + man_file_name + \".csv\"\n",
    "concept_id_col = \"pred_concept_id\"\n",
    "filter_ref_id_col = ref_id_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def csr_vappend(a,b):\n",
    "    \"\"\" Takes in 2 csr_matrices and appends the second one to the bottom of the first one. \n",
    "    Much faster than scipy.sparse.vstack but assumes the type to be csr and overwrites\n",
    "    the first matrix instead of copying it. The data, indices, and indptr still get copied.\"\"\"\n",
    "\n",
    "    a.data = np.hstack((a.data,b.data))\n",
    "    a.indices = np.hstack((a.indices,b.indices))\n",
    "    a.indptr = np.hstack((a.indptr,(b.indptr + a.nnz)[1:]))\n",
    "    a._shape = (a.shape[0]+b.shape[0],b.shape[1])\n",
    "    return a\n",
    "\n",
    "def write_top_words(tops, file_name):\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(\",\".join([\"Concept\", \"Top 5 words\"]))\n",
    "        f.write(\"\\n\")\n",
    "        for group, words in tops.items():\n",
    "            f.write(\",\".join([group, \" \".join(words)]))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "def calc_top_n_words(data_file, \n",
    "                     doc_cols, \n",
    "                     doc_col_key,\n",
    "                     ref_id_col, \n",
    "                     filter_file,\n",
    "                     n,\n",
    "                     concept_id_col,\n",
    "                     filter_ref_id_col, \n",
    "                     word_vectors=None, \n",
    "                     corpora_col=None, \n",
    "                     pair_ids=None):\n",
    "    print data_file\n",
    "    print \"doc_col_key: \" + doc_col_key\n",
    "    data = pd.read_csv(data_file, sep=\",\",quotechar='\"', na_values=\"\",low_memory=False)\n",
    "    \n",
    "    if corpora_col:\n",
    "        corpora_data = corpus.partition(data, corpora_col)\n",
    "    else:\n",
    "        corpora_data = [data]\n",
    "    \n",
    "    if filter_file != data_file:\n",
    "        filter_data = pd.read_csv(filter_file,\n",
    "                                  sep=\",\",\n",
    "                                  quotechar='\"',\n",
    "                                  na_values=\"\",\n",
    "                                  low_memory=False)\n",
    "    else:\n",
    "        filter_data = data\n",
    "        \n",
    "    print(\" Building Corpora...\")\n",
    "    corpora = corpus.build_corpora(doc_cols, corpora_data, ref_id_col, num_cpus=num_cpus)\n",
    "    print(\"Corpus: \", len(corpora), \" \", len([doc for c in corpora for doc in c]))\n",
    "    \n",
    "    print(\"  Calculating BOW matrix...\")\n",
    "    vocab, bow = corpus.calc_tfidf(corpora)\n",
    "    \n",
    "    # calculate embeddings\n",
    "    if word_vectors:\n",
    "        print(\"  Calculating doc embeddings matrix...\")\n",
    "        doc_ids, doc_vectors = corpus.calc_doc_embeddings(bow.toarray(), vocab, word_vectors, corpora)\n",
    "        print(\"doc_ids: \", len(doc_ids), \" vecs: \", len(doc_vectors))\n",
    "    else:\n",
    "        doc_ids = [doc for c in corpora for doc, _ in c]\n",
    "        doc_vectors = bow.toarray()\n",
    "    \n",
    "    \n",
    "    tfidf_label = \"multtfcdf\" if corpora_col else \"tfidf\"\n",
    "    embed_label = \"embed\" if word_vectors else None\n",
    "    \n",
    "    input_data_type = man_file_name\n",
    "    out_file_name = str.join('_', [i for i in [out_prefix, \n",
    "                                               input_data_type, \n",
    "                                               tfidf_label, \n",
    "                                               embed_label, \n",
    "                                               doc_col_key] \n",
    "                                   if i])\n",
    "    out_file = output_dir + out_file_name + \".csv\"\n",
    "    \n",
    "    print(\"  Calculating Top N words..\")\n",
    "    filter_groups = filter_data.groupby([concept_id_col])[filter_ref_id_col]\n",
    "    groups = {group: data[ref_id_col].isin(filter_groups.get_group(group)) for group in list(filter_groups.groups)}\n",
    "    normalzed_doc_vectors_by_group = corpus.normalize_doc_vectors_by_group(doc_vectors, groups)\n",
    "    top_words_in_group = {group: corpus.vec_top_words(vocab, vec, n) for group, vec in normalzed_doc_vectors_by_group.items()}\n",
    "\n",
    "    top_words_out_file_name = str.join('_', [i for i in [top_words_prefix, \n",
    "                                                        man_file_name]\n",
    "                                             if i])\n",
    "    top_words_out_file = output_dir + top_words_out_file_name + \".csv\"\n",
    "    write_top_words(top_words_in_group, top_words_out_file)\n",
    "    \n",
    "    ref_ids = normalzed_doc_vectors_by_group.keys() \n",
    "    \n",
    "    print(\"  Calculating Similarity Scores...\")\n",
    "    scores = vocab_similarity.VariableSimilarityCalculator(ref_ids, pairable=default_pairable)\n",
    "    scores.init_cache(file_name=out_file)\n",
    "\n",
    "    normalzed_doc_vectors_matrix = csr_matrix(np.vstack(normalzed_doc_vectors_by_group.values()))\n",
    "    bow_with_concepts = csr_vappend(bow, normalzed_doc_vectors_matrix)\n",
    "    doc_ids_with_concepts = doc_ids + normalzed_doc_vectors_by_group.keys()\n",
    "\n",
    "    scores.score_variables(doc_ids_with_concepts, \n",
    "                           bow_with_concepts, \n",
    "                           num_cpus=num_cpus, \n",
    "                           file_name=out_file, \n",
    "                           pair_ids=pair_ids)\n",
    "    \n",
    "    \n",
    "    return top_words_in_group\n",
    "\n",
    "def calc_top_n_words_by_doc_cols(data_file, \n",
    "                                 doc_cols_inputs, \n",
    "                                 ref_id_col, \n",
    "                                 filter_file, \n",
    "                                 n, \n",
    "                                 concept_id_col, \n",
    "                                 filter_ref_id_col, \n",
    "                                 corpora_col=None, \n",
    "                                 word_vectors=None, \n",
    "                                 pair_ids=None):\n",
    "    return {key: calc_top_n_words(data_file, \n",
    "                        doc_cols_inputs[key], \n",
    "                        key, \n",
    "                        ref_id_col, \n",
    "                        filter_file, \n",
    "                        n,\n",
    "                        concept_id_col,\n",
    "                        filter_ref_id_col, \n",
    "                        corpora_col=corpora_col, \n",
    "                        word_vectors=word_vectors, \n",
    "                        pair_ids=pair_ids)\n",
    "                for key in doc_cols_inputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Laura/automatic-variable-mapping/SNOMED-concepts/output/var_doc_obs_heart_studies_dbGaP_NLP_SNOMED_terms.csv\n",
      "doc_col_key: desc\n",
      " Building Corpora...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "automatic_variable_mapping/corpus.py:135: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  corpus_data[cols].as_matrix()),\n",
      "  5%|▍         | 6069/133557 [00:03<15:43:47,  2.25it/s]Process PoolWorker-1:\n",
      "Process PoolWorker-9:\n",
      "Process PoolWorker-6:\n",
      "Process PoolWorker-4:\n",
      "Process PoolWorker-2:\n",
      "Process PoolWorker-8:\n",
      "Process PoolWorker-12:\n",
      "Process PoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-5:\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-14:\n",
      "Process PoolWorker-7:\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    result = (True, func(*args, **kwds))\n",
      "    result = (True, func(*args, **kwds))\n",
      "    self.run()\n",
      "    result = (True, func(*args, **kwds))\n",
      "    result = (True, func(*args, **kwds))\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    result = (True, func(*args, **kwds))\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    result = (True, func(*args, **kwds))\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 26, in words\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "    result = (True, func(*args, **kwds))\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "    if not line.startswith(ignore_lines_startswith)\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 140, in line_tokenize\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "KeyboardInterrupt\n",
      "    return LineTokenizer(blanklines).tokenize(text)\n",
      "    result = (True, func(*args, **kwds))\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 117, in tokenize\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 140, in line_tokenize\n",
      "    lines = [l for l in lines if l.rstrip()]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 140, in line_tokenize\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 34, in raw\n",
      "    return LineTokenizer(blanklines).tokenize(text)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 117, in tokenize\n",
      "KeyboardInterrupt\n",
      "    return LineTokenizer(blanklines).tokenize(text)\n",
      "    lines = [l for l in lines if l.rstrip()]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 117, in tokenize\n",
      "KeyboardInterrupt\n",
      "    lines = [l for l in lines if l.rstrip()]\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    return concat([self.open(f).read() for f in fileids])\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/api.py\", line 213, in open\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    stream = self._root.join(file).open(encoding)\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 355, in join\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "    return FileSystemPathPointer(_path)\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/compat.py\", line 228, in _decorator\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 34, in raw\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "    return concat([self.open(f).read() for f in fileids])\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/api.py\", line 213, in open\n",
      "    return init_func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "    stream = self._root.join(file).open(encoding)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 347, in open\n",
      "    stream = SeekableUnicodeStreamReader(stream, encoding)\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/compat.py\", line 228, in _decorator\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 331, in __init__\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    _path = os.path.abspath(_path)\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 34, in raw\n",
      "    return init_func(*args, **kwargs)\n",
      "    return concat([self.open(f).read() for f in fileids])\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1157, in __init__\n",
      "    self._bom = self._check_bom()\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 34, in raw\n",
      "    return concat([self.open(f).read() for f in fileids])\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/api.py\", line 213, in open\n",
      "    stream = self._root.join(file).open(encoding)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 347, in open\n",
      "  File \"/opt/conda/lib/python2.7/posixpath.py\", line 373, in abspath\n",
      "    stream = SeekableUnicodeStreamReader(stream, encoding)\n",
      "    return normpath(path)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/compat.py\", line 228, in _decorator\n",
      "  File \"/opt/conda/lib/python2.7/posixpath.py\", line 351, in normpath\n",
      "    return init_func(*args, **kwargs)\n",
      "    if comp in ('', '.'):\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1157, in __init__\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 26, in words\n",
      "    self._bom = self._check_bom()\n",
      "    if not line.startswith(ignore_lines_startswith)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1520, in _check_bom\n",
      "    bom_info = self._BOM_TABLE.get(enc)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1517, in _check_bom\n",
      "    enc = re.sub('[ -]', '', self.encoding.lower())\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/api.py\", line 213, in open\n",
      "  File \"/opt/conda/lib/python2.7/re.py\", line 155, in sub\n",
      "    stream = self._root.join(file).open(encoding)\n",
      "    return _compile(pattern, flags).sub(repl, string, count)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 355, in join\n",
      "KeyboardInterrupt\n",
      "    return FileSystemPathPointer(_path)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/compat.py\", line 228, in _decorator\n",
      "    return init_func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 332, in __init__\n",
      "    if not os.path.exists(_path):\n",
      "  File \"/opt/conda/lib/python2.7/genericpath.py\", line 26, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "Process PoolWorker-27:\n",
      "Process PoolWorker-17:\n",
      "Process PoolWorker-19:\n",
      "Process PoolWorker-16:\n",
      "Process PoolWorker-28:\n",
      "Process PoolWorker-21:\n",
      "Process PoolWorker-15:\n",
      "Process PoolWorker-18:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-25:\n",
      "Process PoolWorker-24:\n",
      "Process PoolWorker-23:\n",
      "Exception KeyboardInterrupt in <bound method SeekableUnicodeStreamReader.__del__ of <nltk.data.SeekableUnicodeStreamReader object at 0x7fbe486c28d0>> ignored\n",
      "Process PoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-22:\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    result = (True, func(*args, **kwds))\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    result = (True, func(*args, **kwds))\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "    self.run()\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    result = (True, func(*args, **kwds))\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 26, in words\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    result = (True, func(*args, **kwds))\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "    if not line.startswith(ignore_lines_startswith)\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "KeyboardInterrupt\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 140, in line_tokenize\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 140, in line_tokenize\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 26, in words\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    return LineTokenizer(blanklines).tokenize(text)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "    if not line.startswith(ignore_lines_startswith)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 114, in tokenize\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    lines = s.splitlines()\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 34, in raw\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "    self.run()\n",
      "    return concat([self.open(f).read() for f in fileids])\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 34, in raw\n",
      "    return LineTokenizer(blanklines).tokenize(text)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1912, in _morphy\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    result = (True, func(*args, **kwds))\n",
      "    return concat([self.open(f).read() for f in fileids])\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/api.py\", line 213, in open\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    results = filter_forms([form] + forms)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    stream = self._root.join(file).open(encoding)\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1899, in filter_forms\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 347, in open\n",
      "    task = get()\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    stream = SeekableUnicodeStreamReader(stream, encoding)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    result.append(form)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/compat.py\", line 228, in _decorator\n",
      "    return recv()\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "KeyboardInterrupt\n",
      "    return init_func(*args, **kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1157, in __init__\n",
      "    self._bom = self._check_bom()\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1520, in _check_bom\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "    bom_info = self._BOM_TABLE.get(enc)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 26, in words\n",
      "KeyboardInterrupt\n",
      "    if not line.startswith(ignore_lines_startswith)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    lines = [l for l in lines if l.rstrip()]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 117, in tokenize\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 140, in line_tokenize\n",
      "    return LineTokenizer(blanklines).tokenize(text)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 114, in tokenize\n",
      "    lines = s.splitlines()\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "KeyboardInterrupt\n",
      "Process PoolWorker-26:\n",
      "Exception KeyboardInterrupt in <bound method SeekableUnicodeStreamReader.__del__ of <nltk.data.SeekableUnicodeStreamReader object at 0x7fbe21ca2e90>> ignored\n",
      "Process PoolWorker-34:\n",
      "Process PoolWorker-39:\n",
      "Process PoolWorker-37:\n",
      "Process PoolWorker-32:\n",
      "Process PoolWorker-41:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-40:\n",
      "Process PoolWorker-38:\n",
      "Process PoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-33:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-35:\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Process PoolWorker-31:\n",
      "Process PoolWorker-36:\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    result = (True, func(*args, **kwds))\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    result = (True, func(*args, **kwds))\n",
      "    put((job, i, result))\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    wacquire()\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "Traceback (most recent call last):\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "KeyboardInterrupt\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "    result = (True, func(*args, **kwds))\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 34, in raw\n",
      "KeyboardInterrupt\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    self.run()\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1909, in _morphy\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    return concat([self.open(f).read() for f in fileids])\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/api.py\", line 213, in open\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    forms = apply_rules([form])\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 26, in words\n",
      "    stream = self._root.join(file).open(encoding)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1886, in apply_rules\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 26, in words\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 345, in open\n",
      "    form[: -len(old)] + new\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "    if not line.startswith(ignore_lines_startswith)\n",
      "    if not line.startswith(ignore_lines_startswith)\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 140, in line_tokenize\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    stream = open(self._path, 'rb')\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    return LineTokenizer(blanklines).tokenize(text)\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 34, in raw\n",
      "KeyboardInterrupt\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    return concat([self.open(f).read() for f in fileids])\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 26, in words\n",
      "    if not line.startswith(ignore_lines_startswith)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/api.py\", line 213, in open\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    stream = self._root.join(file).open(encoding)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 355, in join\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 25, in words\n",
      "    for line in line_tokenize(self.raw(fileids))\n",
      "    return FileSystemPathPointer(_path)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordlist.py\", line 34, in raw\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/compat.py\", line 228, in _decorator\n",
      "    return concat([self.open(f).read() for f in fileids])\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/api.py\", line 213, in open\n",
      "    return init_func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/tokenize/simple.py\", line 117, in tokenize\n",
      "    stream = self._root.join(file).open(encoding)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 331, in __init__\n",
      "KeyboardInterrupt\n",
      "    lines = [l for l in lines if l.rstrip()]\n",
      "KeyboardInterrupt\n",
      "    _path = os.path.abspath(_path)\n",
      "  File \"/opt/conda/lib/python2.7/posixpath.py\", line 373, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/opt/conda/lib/python2.7/posixpath.py\", line 346, in normpath\n",
      "    path.startswith('//') and not path.startswith('///')):\n",
      "KeyboardInterrupt\n",
      "Process PoolWorker-29:\n",
      "Process PoolWorker-50:\n",
      "Process PoolWorker-54:\n",
      "Process PoolWorker-47:\n",
      "Process PoolWorker-44:\n",
      "Process PoolWorker-46:\n",
      "Process PoolWorker-45:\n",
      "Process PoolWorker-43:\n",
      "Process PoolWorker-48:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-49:\n",
      "Process PoolWorker-42:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    result = (True, func(*args, **kwds))\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    self.run()\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    self.run()\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "    self.__load()\n",
      "    result = (True, func(*args, **kwds))\n",
      "    self.__load()\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "    self.__load()\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    self.__load()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    self.__load()\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "Process PoolWorker-53:\n",
      "    result = (True, func(*args, **kwds))\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "Traceback (most recent call last):\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "    self._load_lemma_pos_offset_map()\n",
      "    self._load_lemma_pos_offset_map()\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1203, in _load_lemma_pos_offset_map\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1203, in _load_lemma_pos_offset_map\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    for i, line in enumerate(self.open('index.%s' % suffix)):\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n",
      "    for i, line in enumerate(self.open('index.%s' % suffix)):\n",
      "    self.run()\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "Process PoolWorker-52:\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1265, in next\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1265, in next\n",
      "    self._load_lemma_pos_offset_map()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "    line = self.readline()\n",
      "    self.__load()\n",
      "    self.__load()\n",
      "    self._load_lemma_pos_offset_map()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    line = self.readline()\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1227, in readline\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1203, in _load_lemma_pos_offset_map\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1216, in _load_lemma_pos_offset_map\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    chars += new_chars\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n",
      "    pos = _next_token()\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "    for i, line in enumerate(self.open('index.%s' % suffix)):\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "KeyboardInterrupt\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1214, in readline\n",
      "    self.run()\n",
      "    self.__load()\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1209, in _next_token\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1265, in next\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n",
      "    self._load_lemma_pos_offset_map()\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "    self.__load()\n",
      "    def _next_token():\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    if self.linebuffer:\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "    result = (True, func(*args, **kwds))\n",
      "    line = self.readline()\n",
      "KeyboardInterrupt\n",
      "    self._load_lemma_pos_offset_map()\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1215, in _load_lemma_pos_offset_map\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1220, in readline\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1225, in _load_lemma_pos_offset_map\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n",
      "    new_chars = self._read(readsize)\n",
      "    lemma = _next_token()\n",
      "    [_next_token() for _ in range(n_pointers)]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "KeyboardInterrupt\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1210, in _next_token\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1458, in _read\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    chars, bytes_decoded = self._incr_decode(bytes)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "    return next(_iter)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "KeyboardInterrupt\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "    self.__load()\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    self._load_lemma_pos_offset_map()\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1228, in _load_lemma_pos_offset_map\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "    n_senses = int(_next_token())\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "    self.__load()\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "    self._load_lemma_pos_offset_map()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1207, in _load_lemma_pos_offset_map\n",
      "    self.__load()\n",
      "    _iter = iter(line.split())\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "KeyboardInterrupt\n",
      "    put((job, i, result))\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n",
      "    self._load_lemma_pos_offset_map()\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1216, in _load_lemma_pos_offset_map\n",
      "    pos = _next_token()\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/data.py\", line 1489, in _incr_decode\n",
      "Process PoolWorker-51:\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1209, in _next_token\n",
      "    self._load_lemma_pos_offset_map()\n",
      "    return self.decode(bytes, 'strict')\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "  File \"/opt/conda/lib/python2.7/encodings/utf_8.py\", line 16, in decode\n",
      "    return codecs.utf_8_decode(input, errors, True)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1207, in _load_lemma_pos_offset_map\n",
      "    _iter = iter(line.split())\n",
      "    self._load_lemma_pos_offset_map()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1228, in _load_lemma_pos_offset_map\n",
      "    n_senses = int(_next_token())\n",
      "KeyboardInterrupt\n",
      "    self._load_lemma_pos_offset_map()\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1207, in _load_lemma_pos_offset_map\n",
      "Traceback (most recent call last):\n",
      "    _iter = iter(line.split())\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    def _next_token():\n",
      "KeyboardInterrupt\n",
      "    result = (True, func(*args, **kwds))\n",
      "    wacquire()\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 110, in helper\n",
      "    return (row[len(doc_col)], lemmatize_variable_documentation(row[:-1]))\n",
      "  File \"automatic_variable_mapping/corpus.py\", line 25, in lemmatize_variable_documentation\n",
      "KeyboardInterrupt\n",
      "    if all([ord(c) in range(0, 128) for c in x]) and x not in stopwords.words(\"english\")]\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/stem/wordnet.py\", line 41, in lemmatize\n",
      "    lemmas = wordnet._morphy(word, pos)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 123, in __getattr__\n",
      "    self.__load()\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/util.py\", line 91, in __load\n",
      "    corpus = self.__reader_cls(root, *self.__args, **self.__kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1152, in __init__\n",
      "    self._load_lemma_pos_offset_map()\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.py\", line 1207, in _load_lemma_pos_offset_map\n",
      "    _iter = iter(line.split())\n",
      "KeyboardInterrupt\n",
      "  5%|▍         | 6069/133557 [00:19<15:43:47,  2.25it/s]Process PoolWorker-56:\n",
      "Process PoolWorker-57:\n",
      "Process PoolWorker-64:\n",
      "Process PoolWorker-62:\n",
      "Process PoolWorker-61:\n",
      "Process PoolWorker-59:\n",
      "Process PoolWorker-63:\n",
      "Process PoolWorker-60:\n",
      "Process PoolWorker-58:\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-67:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-66:\n",
      "Process PoolWorker-68:\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-65:\n",
      "Process PoolWorker-55:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "    put((job, i, result))\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    put((job, i, result))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    put((job, i, result))\n",
      "    put((job, i, result))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "    put((job, i, result))\n",
      "    put((job, i, result))\n",
      "    put((job, i, result))\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "    put((job, i, result))\n",
      "    wacquire()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    wacquire()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "    wacquire()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "    wacquire()\n",
      "    put((job, i, result))\n",
      "KeyboardInterrupt\n",
      "    wacquire()\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "    wacquire()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "    wacquire()\n",
      "    wacquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "    wacquire()\n",
      "    wacquire()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    wacquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "    put((job, i, result))\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "    wacquire()\n",
      "KeyboardInterrupt\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/pool.py\", line 117, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "    wacquire()\n",
      "KeyboardInterrupt\n",
      "    put((job, i, result))\n",
      "  File \"/opt/conda/lib/python2.7/multiprocessing/queues.py\", line 388, in put\n",
      "    wacquire()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "data = pd.read_csv(data_file, sep=\",\",quotechar='\"', na_values=\"\",low_memory=False)\n",
    "pair_ids = list(data[data[\"dbGaP_study_id\"]==\"SNOMED\"][ref_id_col])\n",
    "top_n_words = calc_top_n_words_by_doc_cols(data_file, \n",
    "                                            doc_cols_inputs, \n",
    "                                            ref_id_col, \n",
    "                                            man_file, \n",
    "                                            n,\n",
    "                                            concept_id_col,\n",
    "                                            filter_ref_id_col, \n",
    "                                            word_vectors=None, \n",
    "                                            pair_ids=pair_ids)\n",
    "top_n_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptions for top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concept</th>\n",
       "      <th>Top 5 words</th>\n",
       "      <th>manual_mapped_concept</th>\n",
       "      <th>variable_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>SEATED BP: SYSTOLIC 2ND READING (mmHg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>BLOOD PRESSURE: SYSTOLIC - 2ND READING BY PHYS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>BLOOD PRESSURE: SYSTOLIC - 2ND PHYSICIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>PHYSICIAN SYSTOLIC BP 2ND READING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>PHYSICIAN SYSTOLIC BP 2ND READING (UNEQUAL # O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>BLOOD PRESSURE: SYSTOLIC - 2ND MD READING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>BLOOD PRESSURE: SYSTOLIC - 2ND MD READING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>BLOOD PRESSURE: SYSTOLIC - 2ND MD READING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>SEATED BP: SYSTOLIC 2ND READING (mmHg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>ECG CLINICAL READING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>BP-SYSTOLIC - NURSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>PHYSICIAN - SYSTOLIC BLOOD PRESSURE - 2ND READING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>BLOOD PRESSURE: SYSTOLIC - 2ND MD READING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>SEATED BP: SYSTOLIC 2ND READING (mmHg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>SEATED BP: SYSTOLIC 2ND READING (mmHg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>SEATED BP: SYSTOLIC 2ND READING (mmHg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concept_MESA_Exam1Main_s2bp1</td>\n",
       "      <td>systolic 2nd reading pressure bp</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>2nd systolic blood pressure measurement, systo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concept_MESA_Exam1Main_chda</td>\n",
       "      <td>chd coronary time disease heart</td>\n",
       "      <td>CHD</td>\n",
       "      <td>CORONARY HEART DISEASE (CHD), ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>concept_MESA_Exam1Main_chda</td>\n",
       "      <td>chd coronary time disease heart</td>\n",
       "      <td>CHD</td>\n",
       "      <td>TIME TO CHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>concept_MESA_Exam1Main_d1bp1</td>\n",
       "      <td>diastolic 1st reading pressure blood</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>SEATED BP: DIASTOLIC 1ST READING (mmHg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>concept_MESA_Exam1Main_d1bp1</td>\n",
       "      <td>diastolic 1st reading pressure blood</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>BLOOD PRESSURE, DIASTOLIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>concept_MESA_Exam1Main_d1bp1</td>\n",
       "      <td>diastolic 1st reading pressure blood</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>PHYSICIAN DIASTOLIC BP 2ND READING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>concept_MESA_Exam1Main_d1bp1</td>\n",
       "      <td>diastolic 1st reading pressure blood</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>BLOOD PRESSURE: DIASTOLIC - 1ST MD READING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>concept_MESA_Exam1Main_d1bp1</td>\n",
       "      <td>diastolic 1st reading pressure blood</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>BLOOD PRESSURE: DIASTOLIC - 1ST M.D. READING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>concept_MESA_Exam1Main_d1bp1</td>\n",
       "      <td>diastolic 1st reading pressure blood</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>BLOOD PRESSURE: DIASTOLIC - 1ST MD READING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>concept_MESA_Exam1Main_d1bp1</td>\n",
       "      <td>diastolic 1st reading pressure blood</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>BP-DIASTOLIC- NURSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>concept_MESA_Exam1Main_d1bp1</td>\n",
       "      <td>diastolic 1st reading pressure blood</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>PHYSICIAN - DIASTOLIC BLOOD PRESSURE - 1ST REA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concept_MESA_Exam1Main_d1bp1</td>\n",
       "      <td>diastolic 1st reading pressure blood</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>BLOOD PRESSURE: DIASTOLIC - 1ST MD READING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>concept_MESA_Exam1Main_d1bp1</td>\n",
       "      <td>diastolic 1st reading pressure blood</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>SEATED BP: DIASTOLIC 1ST READING (mmHg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>concept_MESA_Exam1Main_d1bp1</td>\n",
       "      <td>diastolic 1st reading pressure blood</td>\n",
       "      <td>Diastolic Blood Pressure (mmHg)</td>\n",
       "      <td>DIASTOLIC MURMUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>concept_MESA_Exam1Main_s3bp1</td>\n",
       "      <td>systolic bp reading 3rd seated</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>SEATED BP: SYSTOLIC 3RD READING (mmHg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>concept_MESA_Exam1Main_s3bp1</td>\n",
       "      <td>systolic bp reading 3rd seated</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>SEATED BP: SYSTOLIC 3RD READING (mmHg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>concept_MESA_Exam1Main_s3bp1</td>\n",
       "      <td>systolic bp reading 3rd seated</td>\n",
       "      <td>Systolic Blood Pressure (mmHg)</td>\n",
       "      <td>3rd systolic blood pressure measurement, systo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>concept_MESA_Exam1Main_pregn1</td>\n",
       "      <td>pregnancy number history reproductive 1</td>\n",
       "      <td>number of pregnancies</td>\n",
       "      <td># OF PREGNANCIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>concept_MESA_Exam1Main_pregn1</td>\n",
       "      <td>pregnancy number history reproductive 1</td>\n",
       "      <td>number of pregnancies</td>\n",
       "      <td>NUMBER OF PREGNANCIES, EXAM 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>concept_MESA_Exam1Main_pregn1</td>\n",
       "      <td>pregnancy number history reproductive 1</td>\n",
       "      <td>number of pregnancies</td>\n",
       "      <td>Medical History - Female Reproductive History:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>concept_MESA_Exam1Main_pregn1</td>\n",
       "      <td>pregnancy number history reproductive 1</td>\n",
       "      <td>number of pregnancies</td>\n",
       "      <td># OF PREGNANCIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>concept_MESA_Exam1Main_pregn1</td>\n",
       "      <td>pregnancy number history reproductive 1</td>\n",
       "      <td>number of pregnancies</td>\n",
       "      <td># OF PREGNANCIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>concept_MESA_Exam1Main_pregn1</td>\n",
       "      <td>pregnancy number history reproductive 1</td>\n",
       "      <td>number of pregnancies</td>\n",
       "      <td>[Menstrual history and pregnancies]. Number of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>concept_MESA_Exam1Main_pregn1</td>\n",
       "      <td>pregnancy number history reproductive 1</td>\n",
       "      <td>number of pregnancies</td>\n",
       "      <td>NUMBER OF PREGNANCIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE (BEATS/MIN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART: OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE (BEATS/MIN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE (beats/min)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>SEATED HEART RATE (BEATS PER MINUTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>SEATED HEART RATE (BEATS PER MINUTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>Heart rate  [ECG Composite 12 Lead (with adjud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>Heart rate [Cohort, Exam 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>Heart rate [ECG Composite 12 Lead (with adjudi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE  (30 SECONDS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE (30 SECONDS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>HEART RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>concept_MESA_Exam1Main_hrtrate1</td>\n",
       "      <td>rate heart beat 30 seated</td>\n",
       "      <td>Heart Rate (beats/min)</td>\n",
       "      <td>Heart Rate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1094 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Concept  \\\n",
       "0        concept_MESA_Exam1Main_s2bp1   \n",
       "1        concept_MESA_Exam1Main_s2bp1   \n",
       "2        concept_MESA_Exam1Main_s2bp1   \n",
       "3        concept_MESA_Exam1Main_s2bp1   \n",
       "4        concept_MESA_Exam1Main_s2bp1   \n",
       "5        concept_MESA_Exam1Main_s2bp1   \n",
       "6        concept_MESA_Exam1Main_s2bp1   \n",
       "7        concept_MESA_Exam1Main_s2bp1   \n",
       "8        concept_MESA_Exam1Main_s2bp1   \n",
       "9        concept_MESA_Exam1Main_s2bp1   \n",
       "10       concept_MESA_Exam1Main_s2bp1   \n",
       "11       concept_MESA_Exam1Main_s2bp1   \n",
       "12       concept_MESA_Exam1Main_s2bp1   \n",
       "13       concept_MESA_Exam1Main_s2bp1   \n",
       "14       concept_MESA_Exam1Main_s2bp1   \n",
       "15       concept_MESA_Exam1Main_s2bp1   \n",
       "16       concept_MESA_Exam1Main_s2bp1   \n",
       "17        concept_MESA_Exam1Main_chda   \n",
       "18        concept_MESA_Exam1Main_chda   \n",
       "19       concept_MESA_Exam1Main_d1bp1   \n",
       "20       concept_MESA_Exam1Main_d1bp1   \n",
       "21       concept_MESA_Exam1Main_d1bp1   \n",
       "22       concept_MESA_Exam1Main_d1bp1   \n",
       "23       concept_MESA_Exam1Main_d1bp1   \n",
       "24       concept_MESA_Exam1Main_d1bp1   \n",
       "25       concept_MESA_Exam1Main_d1bp1   \n",
       "26       concept_MESA_Exam1Main_d1bp1   \n",
       "27       concept_MESA_Exam1Main_d1bp1   \n",
       "28       concept_MESA_Exam1Main_d1bp1   \n",
       "29       concept_MESA_Exam1Main_d1bp1   \n",
       "...                               ...   \n",
       "1064     concept_MESA_Exam1Main_s3bp1   \n",
       "1065     concept_MESA_Exam1Main_s3bp1   \n",
       "1066     concept_MESA_Exam1Main_s3bp1   \n",
       "1067    concept_MESA_Exam1Main_pregn1   \n",
       "1068    concept_MESA_Exam1Main_pregn1   \n",
       "1069    concept_MESA_Exam1Main_pregn1   \n",
       "1070    concept_MESA_Exam1Main_pregn1   \n",
       "1071    concept_MESA_Exam1Main_pregn1   \n",
       "1072    concept_MESA_Exam1Main_pregn1   \n",
       "1073    concept_MESA_Exam1Main_pregn1   \n",
       "1074  concept_MESA_Exam1Main_hrtrate1   \n",
       "1075  concept_MESA_Exam1Main_hrtrate1   \n",
       "1076  concept_MESA_Exam1Main_hrtrate1   \n",
       "1077  concept_MESA_Exam1Main_hrtrate1   \n",
       "1078  concept_MESA_Exam1Main_hrtrate1   \n",
       "1079  concept_MESA_Exam1Main_hrtrate1   \n",
       "1080  concept_MESA_Exam1Main_hrtrate1   \n",
       "1081  concept_MESA_Exam1Main_hrtrate1   \n",
       "1082  concept_MESA_Exam1Main_hrtrate1   \n",
       "1083  concept_MESA_Exam1Main_hrtrate1   \n",
       "1084  concept_MESA_Exam1Main_hrtrate1   \n",
       "1085  concept_MESA_Exam1Main_hrtrate1   \n",
       "1086  concept_MESA_Exam1Main_hrtrate1   \n",
       "1087  concept_MESA_Exam1Main_hrtrate1   \n",
       "1088  concept_MESA_Exam1Main_hrtrate1   \n",
       "1089  concept_MESA_Exam1Main_hrtrate1   \n",
       "1090  concept_MESA_Exam1Main_hrtrate1   \n",
       "1091  concept_MESA_Exam1Main_hrtrate1   \n",
       "1092  concept_MESA_Exam1Main_hrtrate1   \n",
       "1093  concept_MESA_Exam1Main_hrtrate1   \n",
       "\n",
       "                                  Top 5 words  \\\n",
       "0            systolic 2nd reading pressure bp   \n",
       "1            systolic 2nd reading pressure bp   \n",
       "2            systolic 2nd reading pressure bp   \n",
       "3            systolic 2nd reading pressure bp   \n",
       "4            systolic 2nd reading pressure bp   \n",
       "5            systolic 2nd reading pressure bp   \n",
       "6            systolic 2nd reading pressure bp   \n",
       "7            systolic 2nd reading pressure bp   \n",
       "8            systolic 2nd reading pressure bp   \n",
       "9            systolic 2nd reading pressure bp   \n",
       "10           systolic 2nd reading pressure bp   \n",
       "11           systolic 2nd reading pressure bp   \n",
       "12           systolic 2nd reading pressure bp   \n",
       "13           systolic 2nd reading pressure bp   \n",
       "14           systolic 2nd reading pressure bp   \n",
       "15           systolic 2nd reading pressure bp   \n",
       "16           systolic 2nd reading pressure bp   \n",
       "17            chd coronary time disease heart   \n",
       "18            chd coronary time disease heart   \n",
       "19       diastolic 1st reading pressure blood   \n",
       "20       diastolic 1st reading pressure blood   \n",
       "21       diastolic 1st reading pressure blood   \n",
       "22       diastolic 1st reading pressure blood   \n",
       "23       diastolic 1st reading pressure blood   \n",
       "24       diastolic 1st reading pressure blood   \n",
       "25       diastolic 1st reading pressure blood   \n",
       "26       diastolic 1st reading pressure blood   \n",
       "27       diastolic 1st reading pressure blood   \n",
       "28       diastolic 1st reading pressure blood   \n",
       "29       diastolic 1st reading pressure blood   \n",
       "...                                       ...   \n",
       "1064           systolic bp reading 3rd seated   \n",
       "1065           systolic bp reading 3rd seated   \n",
       "1066           systolic bp reading 3rd seated   \n",
       "1067  pregnancy number history reproductive 1   \n",
       "1068  pregnancy number history reproductive 1   \n",
       "1069  pregnancy number history reproductive 1   \n",
       "1070  pregnancy number history reproductive 1   \n",
       "1071  pregnancy number history reproductive 1   \n",
       "1072  pregnancy number history reproductive 1   \n",
       "1073  pregnancy number history reproductive 1   \n",
       "1074                rate heart beat 30 seated   \n",
       "1075                rate heart beat 30 seated   \n",
       "1076                rate heart beat 30 seated   \n",
       "1077                rate heart beat 30 seated   \n",
       "1078                rate heart beat 30 seated   \n",
       "1079                rate heart beat 30 seated   \n",
       "1080                rate heart beat 30 seated   \n",
       "1081                rate heart beat 30 seated   \n",
       "1082                rate heart beat 30 seated   \n",
       "1083                rate heart beat 30 seated   \n",
       "1084                rate heart beat 30 seated   \n",
       "1085                rate heart beat 30 seated   \n",
       "1086                rate heart beat 30 seated   \n",
       "1087                rate heart beat 30 seated   \n",
       "1088                rate heart beat 30 seated   \n",
       "1089                rate heart beat 30 seated   \n",
       "1090                rate heart beat 30 seated   \n",
       "1091                rate heart beat 30 seated   \n",
       "1092                rate heart beat 30 seated   \n",
       "1093                rate heart beat 30 seated   \n",
       "\n",
       "                manual_mapped_concept  \\\n",
       "0      Systolic Blood Pressure (mmHg)   \n",
       "1      Systolic Blood Pressure (mmHg)   \n",
       "2      Systolic Blood Pressure (mmHg)   \n",
       "3      Systolic Blood Pressure (mmHg)   \n",
       "4      Systolic Blood Pressure (mmHg)   \n",
       "5      Systolic Blood Pressure (mmHg)   \n",
       "6      Systolic Blood Pressure (mmHg)   \n",
       "7      Systolic Blood Pressure (mmHg)   \n",
       "8      Systolic Blood Pressure (mmHg)   \n",
       "9      Systolic Blood Pressure (mmHg)   \n",
       "10     Systolic Blood Pressure (mmHg)   \n",
       "11     Systolic Blood Pressure (mmHg)   \n",
       "12     Systolic Blood Pressure (mmHg)   \n",
       "13     Systolic Blood Pressure (mmHg)   \n",
       "14     Systolic Blood Pressure (mmHg)   \n",
       "15     Systolic Blood Pressure (mmHg)   \n",
       "16     Systolic Blood Pressure (mmHg)   \n",
       "17                                CHD   \n",
       "18                                CHD   \n",
       "19    Diastolic Blood Pressure (mmHg)   \n",
       "20    Diastolic Blood Pressure (mmHg)   \n",
       "21    Diastolic Blood Pressure (mmHg)   \n",
       "22    Diastolic Blood Pressure (mmHg)   \n",
       "23    Diastolic Blood Pressure (mmHg)   \n",
       "24    Diastolic Blood Pressure (mmHg)   \n",
       "25    Diastolic Blood Pressure (mmHg)   \n",
       "26    Diastolic Blood Pressure (mmHg)   \n",
       "27    Diastolic Blood Pressure (mmHg)   \n",
       "28    Diastolic Blood Pressure (mmHg)   \n",
       "29    Diastolic Blood Pressure (mmHg)   \n",
       "...                               ...   \n",
       "1064   Systolic Blood Pressure (mmHg)   \n",
       "1065   Systolic Blood Pressure (mmHg)   \n",
       "1066   Systolic Blood Pressure (mmHg)   \n",
       "1067            number of pregnancies   \n",
       "1068            number of pregnancies   \n",
       "1069            number of pregnancies   \n",
       "1070            number of pregnancies   \n",
       "1071            number of pregnancies   \n",
       "1072            number of pregnancies   \n",
       "1073            number of pregnancies   \n",
       "1074           Heart Rate (beats/min)   \n",
       "1075           Heart Rate (beats/min)   \n",
       "1076           Heart Rate (beats/min)   \n",
       "1077           Heart Rate (beats/min)   \n",
       "1078           Heart Rate (beats/min)   \n",
       "1079           Heart Rate (beats/min)   \n",
       "1080           Heart Rate (beats/min)   \n",
       "1081           Heart Rate (beats/min)   \n",
       "1082           Heart Rate (beats/min)   \n",
       "1083           Heart Rate (beats/min)   \n",
       "1084           Heart Rate (beats/min)   \n",
       "1085           Heart Rate (beats/min)   \n",
       "1086           Heart Rate (beats/min)   \n",
       "1087           Heart Rate (beats/min)   \n",
       "1088           Heart Rate (beats/min)   \n",
       "1089           Heart Rate (beats/min)   \n",
       "1090           Heart Rate (beats/min)   \n",
       "1091           Heart Rate (beats/min)   \n",
       "1092           Heart Rate (beats/min)   \n",
       "1093           Heart Rate (beats/min)   \n",
       "\n",
       "                                   variable_description  \n",
       "0                SEATED BP: SYSTOLIC 2ND READING (mmHg)  \n",
       "1     BLOOD PRESSURE: SYSTOLIC - 2ND READING BY PHYS...  \n",
       "2              BLOOD PRESSURE: SYSTOLIC - 2ND PHYSICIAN  \n",
       "3                     PHYSICIAN SYSTOLIC BP 2ND READING  \n",
       "4     PHYSICIAN SYSTOLIC BP 2ND READING (UNEQUAL # O...  \n",
       "5             BLOOD PRESSURE: SYSTOLIC - 2ND MD READING  \n",
       "6             BLOOD PRESSURE: SYSTOLIC - 2ND MD READING  \n",
       "7             BLOOD PRESSURE: SYSTOLIC - 2ND MD READING  \n",
       "8                SEATED BP: SYSTOLIC 2ND READING (mmHg)  \n",
       "9                                  ECG CLINICAL READING  \n",
       "10                                  BP-SYSTOLIC - NURSE  \n",
       "11    PHYSICIAN - SYSTOLIC BLOOD PRESSURE - 2ND READING  \n",
       "12            BLOOD PRESSURE: SYSTOLIC - 2ND MD READING  \n",
       "13               SEATED BP: SYSTOLIC 2ND READING (mmHg)  \n",
       "14               SEATED BP: SYSTOLIC 2ND READING (mmHg)  \n",
       "15               SEATED BP: SYSTOLIC 2ND READING (mmHg)  \n",
       "16    2nd systolic blood pressure measurement, systo...  \n",
       "17                    CORONARY HEART DISEASE (CHD), ALL  \n",
       "18                                          TIME TO CHD  \n",
       "19              SEATED BP: DIASTOLIC 1ST READING (mmHg)  \n",
       "20                            BLOOD PRESSURE, DIASTOLIC  \n",
       "21                   PHYSICIAN DIASTOLIC BP 2ND READING  \n",
       "22           BLOOD PRESSURE: DIASTOLIC - 1ST MD READING  \n",
       "23         BLOOD PRESSURE: DIASTOLIC - 1ST M.D. READING  \n",
       "24           BLOOD PRESSURE: DIASTOLIC - 1ST MD READING  \n",
       "25                                  BP-DIASTOLIC- NURSE  \n",
       "26    PHYSICIAN - DIASTOLIC BLOOD PRESSURE - 1ST REA...  \n",
       "27           BLOOD PRESSURE: DIASTOLIC - 1ST MD READING  \n",
       "28              SEATED BP: DIASTOLIC 1ST READING (mmHg)  \n",
       "29                                     DIASTOLIC MURMUR  \n",
       "...                                                 ...  \n",
       "1064             SEATED BP: SYSTOLIC 3RD READING (mmHg)  \n",
       "1065             SEATED BP: SYSTOLIC 3RD READING (mmHg)  \n",
       "1066  3rd systolic blood pressure measurement, systo...  \n",
       "1067                                   # OF PREGNANCIES  \n",
       "1068                      NUMBER OF PREGNANCIES, EXAM 1  \n",
       "1069  Medical History - Female Reproductive History:...  \n",
       "1070                                   # OF PREGNANCIES  \n",
       "1071                                   # OF PREGNANCIES  \n",
       "1072  [Menstrual history and pregnancies]. Number of...  \n",
       "1073                              NUMBER OF PREGNANCIES  \n",
       "1074                             HEART RATE (BEATS/MIN)  \n",
       "1075                                       HEART: OTHER  \n",
       "1076                             HEART RATE (BEATS/MIN)  \n",
       "1077                             HEART RATE (beats/min)  \n",
       "1078               SEATED HEART RATE (BEATS PER MINUTE)  \n",
       "1079               SEATED HEART RATE (BEATS PER MINUTE)  \n",
       "1080  Heart rate  [ECG Composite 12 Lead (with adjud...  \n",
       "1081                        Heart rate [Cohort, Exam 2]  \n",
       "1082  Heart rate [ECG Composite 12 Lead (with adjudi...  \n",
       "1083                           HEART RATE  (30 SECONDS)  \n",
       "1084                            HEART RATE (30 SECONDS)  \n",
       "1085                                         HEART RATE  \n",
       "1086                                         HEART RATE  \n",
       "1087                                         HEART RATE  \n",
       "1088                                         HEART RATE  \n",
       "1089                                         HEART RATE  \n",
       "1090                                         HEART RATE  \n",
       "1091                                         HEART RATE  \n",
       "1092                                         HEART RATE  \n",
       "1093                                         Heart Rate  \n",
       "\n",
       "[1094 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "output_file_name = \"top_n_words_concept_groups_reference_MESA_vars\"\n",
    "top_n_data = pd.read_csv(output_dir + output_file_name + \".csv\")\n",
    "man_file_name = \"concept_groups_reference_MESA_vars\"\n",
    "man_file = \"/Laura/tiff_laura_shared/\" + \"\" + man_file_name + \".csv\"\n",
    "man_data = pd.read_csv(man_file, sep=\",\",quotechar='\"', na_values=\"\",low_memory=False)\n",
    "cols = [\"Concept\", \"Top 5 words\", \"manual_mapped_concept\", \"variable_description\"]\n",
    "top_n_data_with_desc = pd.merge(top_n_data, man_data, left_on=\"Concept\", right_on=\"pred_concept_id\")[cols]\n",
    "top_n_data_with_desc.to_csv(output_dir + output_file_name + \"_with_desc\" + \".csv\")\n",
    "top_n_data_with_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 pairs with descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_pairs_with_desc(sim_data):\n",
    "    top_5_pairs = sim_data.sort_values([\"score\"], ascending=[False]).groupby(\"reference var\").head(5)\n",
    "    cols = [\"reference var\", \"paired var\", \"score\", \"variable_description\"]\n",
    "    return pd.merge(top_5_pairs, snomed_data, left_on=\"paired var\", right_on=ref_id_col)[cols]\n",
    "    \n",
    "def read_then_top_5_then_write(output_file_name):\n",
    "    sim_data = pd.read_csv(output_dir + output_file_name + \".csv\")\n",
    "    top_n_data_with_desc = top_5_pairs_with_desc(sim_data)\n",
    "    top_n_data_with_desc.to_csv(output_dir + output_file_name + \"_top_5_with_desc\" + \".csv\")\n",
    "\n",
    "data = pd.read_csv(data_file, sep=\",\",quotechar='\"', na_values=\"\",low_memory=False)\n",
    "snomed_data =  data[data[\"dbGaP_study_id\"]==\"SNOMED\"]\n",
    "  \n",
    "output_file_name = \"concept_vec_sim_scores_concept_groups_communities_tfidf_desc\"\n",
    "read_then_top_5_then_write(output_file_name)\n",
    "\n",
    "output_file_name = \"concept_vec_sim_scores_concept_groups_reference_MESA_vars_tfidf_desc\"\n",
    "read_then_top_5_then_write(output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intra-Concept similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cosine_sim_prefix = \"group_sim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_group_cosine_sim(data_file, \n",
    "                     doc_cols, \n",
    "                     doc_col_key,\n",
    "                     ref_id_col, \n",
    "                     filter_file,\n",
    "                     n,\n",
    "                     concept_id_col,\n",
    "                     filter_ref_id_col, \n",
    "                     corpora_col=None):\n",
    "    print data_file\n",
    "    print \"doc_col_key: \" + doc_col_key\n",
    "    data = pd.read_csv(data_file, sep=\",\",quotechar='\"', na_values=\"\",low_memory=False)\n",
    "    \n",
    "    if corpora_col:\n",
    "        corpora_data = corpus.partition(data, corpora_col)\n",
    "    else:\n",
    "        corpora_data = [data]\n",
    "    \n",
    "    if filter_file != data_file:\n",
    "        filter_data = pd.read_csv(filter_file,\n",
    "                                  sep=\",\",\n",
    "                                  quotechar='\"',\n",
    "                                  na_values=\"\",\n",
    "                                  low_memory=False)\n",
    "    else:\n",
    "        filter_data = data\n",
    "        \n",
    "    print(\" Building Corpora...\")\n",
    "    corpora = corpus.build_corpora(doc_cols, corpora_data, ref_id_col, num_cpus=num_cpus)\n",
    "    print(\"Corpus: \", len(corpora), \" \", len([doc for c in corpora for doc in c]))\n",
    "    \n",
    "    print(\"  Calculating BOW matrix...\")\n",
    "    vocab, bow = corpus.calc_tfidf(corpora)\n",
    "    doc_vectors = bow.toarray()\n",
    "    \n",
    "    tfidf_label = \"multtfcdf\" if corpora_col else \"tfidf\"\n",
    "\n",
    "    filter_groups = filter_data.groupby([concept_id_col])[filter_ref_id_col]\n",
    "    groups = {group: data[ref_id_col].isin(filter_groups.get_group(group)) for group in list(filter_groups.groups)}\n",
    "\n",
    "    group_sim = pd.DataFrame(columns=[\"Concept\", \"Similarity\"])\n",
    "    for group, group_indices in groups.items():\n",
    "        group_vectors = doc_vectors[group_indices]\n",
    "        sim = np.matmul(group_vectors, group_vectors.transpose())\n",
    "        upper_tri = [sim[i][j] for i in range(1, sim.shape[0]) for j in range(0, i)]\n",
    "        group_sim.loc[len(group_sim.index)] = [group, np.mean(np.array(upper_tri))]\n",
    "\n",
    "\n",
    "    top_words_out_file_name = str.join('_', [i for i in [group_cosine_sim_prefix, \n",
    "                                                    man_file_name]\n",
    "                                         if i])\n",
    "    top_words_out_file = output_dir + top_words_out_file_name + \".csv\"\n",
    "    group_sim.to_csv(top_words_out_file)\n",
    "    \n",
    "    \n",
    "    return group_sim\n",
    "\n",
    "def calc_cosine_sims(data_file, \n",
    "                                 doc_cols_inputs, \n",
    "                                 ref_id_col, \n",
    "                                 filter_file, \n",
    "                                 n, \n",
    "                                 concept_id_col, \n",
    "                                 filter_ref_id_col, \n",
    "                                 corpora_col=None):\n",
    "    return {key: calc_group_cosine_sim(data_file, \n",
    "                        doc_cols_inputs[key], \n",
    "                        key, \n",
    "                        ref_id_col, \n",
    "                        filter_file, \n",
    "                        n,\n",
    "                        concept_id_col,\n",
    "                        filter_ref_id_col, \n",
    "                        corpora_col=corpora_col)\n",
    "                for key in doc_cols_inputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Laura/automatic-variable-mapping/SNOMED-concepts/output/var_doc_obs_heart_studies_dbGaP_NLP_SNOMED_terms.csv\n",
      "doc_col_key: desc\n",
      " Building Corpora...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133557/133557 [00:18<00:00, 7218.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Corpus: ', 1, ' ', 133557)\n",
      "  Calculating BOW matrix...\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "cosine_sims = calc_cosine_sims(data_file, \n",
    "                                            doc_cols_inputs, \n",
    "                                            ref_id_col, \n",
    "                                            man_file, \n",
    "                                            n,\n",
    "                                            concept_id_col,\n",
    "                                            filter_ref_id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_col_key = \"desc\"  \n",
    "filter_file = man_file\n",
    "corpora_col = None\n",
    "key = \"desc\"\n",
    "doc_cols = doc_cols_inputs[key]\n",
    "pair_ids_col = ref_id_col"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
